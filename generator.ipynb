{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alaney2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import shutil\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "from dotenv import load_dotenv\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "load_dotenv('.env.local')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(topic):\n",
    "    parts = topic.split('_')\n",
    "    parts = [part.capitalize() for part in parts]\n",
    "    topic = ' '.join(parts)\n",
    "    prompt = f'Topic: {topic}\\n' + '''\n",
    "    You are a world-renowned AI and ML expert.\n",
    "    Provide a JSON object containing the topic, a list of 0-8 prerequisite topics, and a list of 0-8 further readings related to AI, ML, and DL.\n",
    "    The name of the JSON object must match exactly with the given topic.\n",
    "    Ensure that the prerequisites and further readings are specifically relevant to the given, rather than broad topics like calculus or statistics.\n",
    "    When generating topics, prefer the singular form of the topic, such as \"convolutional_neural_network\" instead of \"convolutional_neural_networks\" but use the plural form when it makes more sense to (\"policy_gradient_methods\").\n",
    "    Ensure that the title field is properly capitalized and spaced and has the right punctuation (such as Q-Learning).\n",
    "    Also ensure that the topic, prerequisites, and further readings are in snake_case (no dashes). Do not put single quotes anywhere in the JSON object.\n",
    "    Use a similar format to the example provided below and ensure that the JSON object is valid.\n",
    "\n",
    "    Example:\n",
    "    {\n",
    "        \"generative_adversarial_network\": {\n",
    "            \"title\": \"Generative Adversarial Network\",\n",
    "            \"prerequisites\": [\"expectation_maximization_algorithm\", \"probability_distributions\", \"convolutional_neural_networks\", \"backpropagation\", \"stochastic_gradient_descent\", \"loss_functions\", \"optimization_algorithms\", \"deep_learning_frameworks\", \"regularization_techniques\", \"unsupervised_learning\"],\n",
    "            \"further_readings\": [\"conditional_gans\", \"cycle_gans\", \"stylegan_and_stylegan2\", \"wasserstein_gans\", \"domain_adaptation\", \"image_to_image_translation\", \"semi_supervised_learning\", \"adversarial_training\", \"adversarial_attacks_and_defenses\", \"transfer_learning\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Next, write a detailed wiki page about the given topic in Markdown format. Always write from a third-person perspective and remain unopinionated.\n",
    "    Ensure that this wiki page is explicitly in code format. \n",
    "    Do not include a \"Contents\" section. \n",
    "    Do not include a \"Further Readings\" nor a \"Prerequisites\" section if they just include related topics.\n",
    "    Use a neutral, unbiased tone without exclamation marks. \n",
    "    Ensure that the heading is the same as the title in the JSON object.\n",
    "    Follow Markdown syntax for headings and formatting, and use LaTeX for equations, with inline equations in pairs of $ and multiline equations in $$.\n",
    "    Ensure the entire output is less than 3600 tokens long and does not include an extra line at the end of the Markdown.\n",
    "    '''\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_completion(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    finish_reason = completion.choices[0]['finish_reason']\n",
    "    message = completion.choices[0].message.content\n",
    "    return finish_reason, message, completion\n",
    "\n",
    "\n",
    "def generate_json(message, topic):\n",
    "    message = message.strip()\n",
    "    json_string = re.search(r'(?s){\\s*\\\"[^\"]+\\\":\\s*{.*?}\\s*}', message, re.DOTALL)\n",
    "    \n",
    "    if json_string:\n",
    "        json_string = json_string.group()\n",
    "        # json_string = json_string.lower()\n",
    "        json_string = re.sub(r',\\s*([\\]}])', r'\\1', json_string)\n",
    "        json_object = json.loads(json_string)\n",
    "        # title_words = json_object[topic]['title'].split()\n",
    "        # result_title = [word.capitalize() if word.lower() not in stop_words else word for word in title_words]\n",
    "        # result_title = \" \".join(result_title)\n",
    "        # json_object[topic]['title'] = result_title\n",
    "        # print(json_object[topic]['title'])\n",
    "\n",
    "        # if topic not in json_string:\n",
    "        #     print(\"Error: Could not find topic in JSON.\")\n",
    "        #     exit(1)\n",
    "        with open('wiki-connections.json', 'r') as file:\n",
    "            existing_data = json.load(file)\n",
    "        existing_data.update(json_object)\n",
    "        with open('wiki-connections.json', 'w') as file:\n",
    "            json.dump(existing_data, file, indent=4)\n",
    "    else:\n",
    "        print(\"Error: Could not extract JSON from message.\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "def generate_markdown(message, topic):\n",
    "    message = message.strip()\n",
    "    markdown_start_pos = message.find('#')\n",
    "    markdown_content = message[markdown_start_pos:].strip() + '\\n'\n",
    "\n",
    "    md_filename = topic + '.md'\n",
    "    with open(md_filename, 'w') as file:\n",
    "        file.write(markdown_content)\n",
    "\n",
    "    destination_folder = 'data'\n",
    "    shutil.move(md_filename, destination_folder)\n",
    "\n",
    "\n",
    "def generate_js(topic):\n",
    "    md_filename = topic + '.md'\n",
    "    js_string = f'''\n",
    "    import React from 'react';\n",
    "    import path from 'path';\n",
    "    import fs from 'fs';\n",
    "    import PageContent from '@/components/PageContent/PageContent';\n",
    "\n",
    "    const filename = '{md_filename}';\n",
    "\n",
    "    export default function MarkdownPage({{ markdownContent }}) {{\n",
    "    return <PageContent content={{markdownContent}} filename={{filename}} />;\n",
    "    }}\n",
    "\n",
    "    export async function getStaticProps() {{\n",
    "    const filePath = path.join(process.cwd(), 'data', filename);\n",
    "    const markdownContent = fs.readFileSync(filePath, 'utf8');\n",
    "    return {{\n",
    "        props: {{\n",
    "        markdownContent,\n",
    "        }},\n",
    "    }};\n",
    "    }}\n",
    "    '''\n",
    "    js_filename = topic + '.js'\n",
    "    with open(js_filename, 'w') as file:\n",
    "        file.write(js_string)\n",
    "\n",
    "    destination_folder = 'pages'\n",
    "    shutil.move(js_filename, destination_folder)\n",
    "\n",
    "\n",
    "def extract_markdown(message):\n",
    "    markdown_start = message.find('```')\n",
    "    markdown_end = message.rfind('```')\n",
    "    markdown_string = message[markdown_start:markdown_end+3]\n",
    "    return markdown_string\n",
    "\n",
    "\n",
    "def save_visited_pages(visited_pages, file_name='visited_pages.pickle'):\n",
    "    with open(file_name, 'wb') as handle:\n",
    "        pickle.dump(visited_pages, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_visited_pages(file_name='visited_pages.pickle'):\n",
    "    try:\n",
    "        with open(file_name, 'rb') as handle:\n",
    "            visited_pages = pickle.load(handle)\n",
    "        return visited_pages\n",
    "    except FileNotFoundError:\n",
    "        return set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_pages = load_visited_pages()\n",
    "visited_pages.update([''])\n",
    "save_visited_pages(visited_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW GENERATING: discrete_distributions\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"discrete_distributions\": {\n",
      "        \"title\": \"Discrete Distributions\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"binomial_distribution\", \"poisson_distribution\"],\n",
      "        \"further_readings\": [\"negative_binomial_distribution\", \"geometric_distribution\", \"hypergeometric_distribution\", \"multinomial_distribution\", \"conditional_probability\", \"expected_value_and_variance\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Discrete Distributions\n",
      "\n",
      "Discrete distributions are a type of probability distribution that describes the probability of each possible outcome in a discrete set of values. They are commonly used in statistics and probability theory to model random variables that can take only a finite or countably infinite number of values.\n",
      "\n",
      "## Probability Mass Function (PMF)\n",
      "\n",
      "The probability mass function (PMF) of a discrete distribution gives the probability of each possible outcome in the set of values that the random variable can take. It is a function that maps each possible outcome to its probability. The PMF must satisfy two conditions:\n",
      "\n",
      "1. The PMF is non-negative for every possible outcome.\n",
      "2. The sum of the PMF over all possible outcomes is equal to one.\n",
      "\n",
      "The PMF can be written as:\n",
      "\n",
      "$$P(X = x_i) = p_i$$\n",
      "\n",
      "where $X$ is the random variable, $x_i$ is a possible outcome, and $p_i$ is the probability of $X$ taking the value $x_i$.\n",
      "\n",
      "## Examples of Discrete Distributions\n",
      "\n",
      "### Bernoulli Distribution\n",
      "\n",
      "The Bernoulli distribution is a discrete distribution that models a single trial of a binary experiment, where the outcome is either success or failure. The PMF of a Bernoulli distribution is:\n",
      "\n",
      "$$P(X = x) = p^x(1-p)^{1-x}$$\n",
      "\n",
      "where $p$ is the probability of success and $x$ is 0 for failure and 1 for success.\n",
      "\n",
      "### Binomial Distribution\n",
      "\n",
      "The binomial distribution is a discrete distribution that models the number of successes in a fixed number of independent and identically distributed (i.i.d.) trials of a binary experiment. The PMF of a binomial distribution is:\n",
      "\n",
      "$$P(X = k) = {{n}\\choose{k}}p^k(1-p)^{n-k}$$\n",
      "\n",
      "where $n$ is the number of trials, $k$ is the number of successes, $p$ is the probability of success in a single trial, and ${n\\choose k}$ is the binomial coefficient.\n",
      "\n",
      "### Poisson Distribution\n",
      "\n",
      "The Poisson distribution is a discrete distribution that models the number of events occurring in a fixed interval of time or space, where the events are rare and independent. The PMF of a Poisson distribution is:\n",
      "\n",
      "$$P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$\n",
      "\n",
      "where $\\lambda$ is the average rate of events per interval and $k$ is the number of events.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Discrete distributions are a fundamental concept in probability theory and statistics. They provide a way to model random variables that can take only a finite or countably infinite number of values. The PMF of a discrete distribution gives the probability of each possible outcome, subject to the two conditions that it must be non-negative and sum to one. The Bernoulli, binomial, and Poisson distributions are examples of commonly used discrete distributions.\n",
      "DONE GENERATING: discrete_distributions\n",
      "NOW GENERATING: continuous_distributions\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"continuous_distributions\": {\n",
      "        \"title\": \"Continuous Distributions\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"calculus\", \"statistics\"],\n",
      "        \"further_readings\": [\"normal_distribution\", \"exponential_distribution\", \"beta_distribution\", \"gamma_distribution\", \"weibull_distribution\", \"lognormal_distribution\", \"chi_squared_distribution\", \"student's_t_distribution\", \"F_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Continuous Distributions\n",
      "\n",
      "Continuous distributions are a type of probability distribution where the random variable takes on any value within a certain interval or range. This is in contrast to discrete distributions, where the random variable can only take on certain specific values. \n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) is used to describe the distribution of continuous random variables. It is a function that describes the relative likelihood of observing a value of the random variable. The area under the PDF curve between any two values of the random variable represents the probability of the random variable assuming a value within that range.\n",
      "\n",
      "The PDF must satisfy the following properties:\n",
      "* $f(x) \\geq 0$ for all $x$.\n",
      "* $\\int_{-\\infty}^{\\infty} f(x) dx = 1$.\n",
      "\n",
      "## Examples of Continuous Distributions\n",
      "\n",
      "### Normal Distribution\n",
      "\n",
      "The normal distribution is one of the most commonly used continuous distributions. It is also known as the Gaussian distribution. The normal distribution is symmetric, bell-shaped, and defined by two parameters: the mean $\\mu$ and the standard deviation $\\sigma$. The PDF of the normal distribution is given by:\n",
      "\n",
      "$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} $$\n",
      "\n",
      "### Exponential Distribution\n",
      "\n",
      "The exponential distribution is a continuous distribution that is often used to model the time between events in a Poisson process. The PDF of the exponential distribution is given by:\n",
      "\n",
      "$$ f(x) = \\begin{cases} \\lambda e^{-\\lambda x} & x \\geq 0 \\\\ 0 & x < 0 \\end{cases} $$\n",
      "\n",
      "where $\\lambda$ is the rate parameter.\n",
      "\n",
      "### Beta Distribution\n",
      "\n",
      "The beta distribution is a continuous distribution that is often used to model proportions or probabilities. The PDF of the beta distribution is given by:\n",
      "\n",
      "$$ f(x) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)} $$\n",
      "\n",
      "where $\\alpha$ and $\\beta$ are shape parameters and $B(\\alpha,\\beta)$ is the beta function.\n",
      "\n",
      "### Gamma Distribution\n",
      "\n",
      "The gamma distribution is a continuous distribution that is often used to model waiting times or survival times. The PDF of the gamma distribution is given by:\n",
      "\n",
      "$$ f(x) = \\frac{x^{\\alpha-1}e^{-\\frac{x}{\\beta}}}{\\beta^\\alpha \\Gamma(\\alpha)} $$\n",
      "\n",
      "where $\\alpha$ and $\\beta$ are shape and scale parameters, respectively, and $\\Gamma(\\alpha)$ is the gamma function.\n",
      "\n",
      "### Weibull Distribution\n",
      "\n",
      "The Weibull distribution is a continuous distribution that is often used to model failure times or lifetimes. The PDF of the Weibull distribution is given by:\n",
      "\n",
      "$$ f(x) = \\begin{cases} \\frac{\\alpha}{\\beta} (\\frac{x}{\\beta})^{\\alpha-1} e^{-(\\frac{x}{\\beta})^\\alpha} & x \\geq 0 \\\\ 0 & x < 0 \\end{cases} $$\n",
      "\n",
      "where $\\alpha$ and $\\beta$ are shape and scale parameters, respectively.\n",
      "\n",
      "### Lognormal Distribution\n",
      "\n",
      "The lognormal distribution is a continuous distribution that is often used to model the distribution of product of random variables. The PDF of the lognormal distribution is given by:\n",
      "\n",
      "$$ f(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}} e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}} $$\n",
      "\n",
      "where $\\mu$ and $\\sigma$ are the mean and standard deviation of the logarithm of the random variable, respectively.\n",
      "\n",
      "### Chi-Squared Distribution\n",
      "\n",
      "The chi-squared distribution is a continuous distribution that is often used in hypothesis testing. The PDF of the chi-squared distribution is given by:\n",
      "\n",
      "$$ f(x) = \\begin{cases} \\frac{1}{2^{\\frac{k}{2}}\\Gamma(\\frac{k}{2})} x^{\\frac{k}{2}-1} e^{-\\frac{x}{2}} & x \\geq 0 \\\\ 0 & x < 0 \\end{cases} $$\n",
      "\n",
      "where $k$ is the degrees of freedom and $\\Gamma(\\frac{k}{2})$ is the gamma function.\n",
      "\n",
      "### Student's t-Distribution\n",
      "\n",
      "The Student's t-distribution is a continuous distribution that is often used in hypothesis testing when the sample size is small or when the population variance is unknown. The PDF of the Student's t-distribution is given by:\n",
      "\n",
      "$$ f(x) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{x^2}{\\nu}\\right)^{-\\frac{\\nu+1}{2}} $$\n",
      "\n",
      "where $\\nu$ is the degrees of freedom and $\\Gamma(\\frac{\\nu}{2})$ is the gamma function.\n",
      "\n",
      "### F-Distribution\n",
      "\n",
      "The F-distribution is a continuous distribution that is often used in hypothesis testing for comparing variances of two populations. The PDF of the F-distribution is given by:\n",
      "\n",
      "$$ f(x) = \\begin{cases} \\frac{\\sqrt{\\frac{(df_1x)^{df_1}df_2^{df_2}}{(df_1x+df_2)^{df_1+df_2}}}}{xB(\\frac{df_1}{2},\\frac{df_2}{2})} & x \\geq 0 \\\\ 0 & x < 0 \\end{cases} $$\n",
      "\n",
      "where $df_1$ and $df_2$ are the degrees of freedom for the numerator and denominator, respectively, and $B(\\frac{df_1}{2},\\frac{df_2}{2})$ is the beta function.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Continuous distributions are a fundamental concept in probability theory and statistics. They are used to model a wide range of phenomena in the natural and social sciences. In this article, several common continuous distributions were introduced, along with their probability density functions.\n",
      "DONE GENERATING: continuous_distributions\n",
      "NOW GENERATING: bernoulli_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"bernoulli_distribution\": {\n",
      "        \"title\": \"Bernoulli Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"expectation_and_variance\", \"binomial_distribution\", \"multinomial_distribution\", \"random_variables\"],\n",
      "        \"further_readings\": [\"geometric_distribution\", \"negative_binomial_distribution\", \"hypergeometric_distribution\", \"poisson_distribution\", \"exponential_distribution\", \"gamma_distribution\", \"beta_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Bernoulli Distribution\n",
      "\n",
      "Bernoulli distribution is a discrete probability distribution that takes the value 1 with probability *p* and the value 0 with probability *1 - p*, where *p* is a parameter of the distribution. It is a special case of the binomial distribution, where the number of trials is 1. \n",
      "\n",
      "Bernoulli distribution is commonly used in various areas of statistics, machine learning, and artificial intelligence, particularly in binary classification problems. It has a simple mathematical form and can be used to model events that have only two possible outcomes such as success or failure, heads or tails, or yes or no.\n",
      "\n",
      "## Probability Mass Function\n",
      "\n",
      "The probability mass function (PMF) of a Bernoulli distribution with parameter *p* is defined as:\n",
      "\n",
      "$$P(X=k) = p^k(1-p)^{1-k}$$\n",
      "\n",
      "where *k* is either 0 or 1.\n",
      "\n",
      "## Mean and Variance\n",
      "\n",
      "The mean (or expected value) of a Bernoulli distribution is given by:\n",
      "\n",
      "$$E(X) = p$$\n",
      "\n",
      "and the variance is given by:\n",
      "\n",
      "$$Var(X) = p(1-p)$$\n",
      "\n",
      "## Applications\n",
      "\n",
      "Bernoulli distribution has several applications in various fields, including:\n",
      "\n",
      "- **Binary classification**: In machine learning, Bernoulli distribution is used to model binary classification problems where the goal is to predict whether an input belongs to one of two classes.\n",
      "- **A/B testing**: Bernoulli distribution is used in A/B testing to model the probability of a user taking a particular action (such as clicking on a button) given a particular variation of a website.\n",
      "- **Randomized algorithms**: Bernoulli distribution is used in randomized algorithms to simulate coin flips or other binary choices.\n",
      "- **Signal detection theory**: In psychology, Bernoulli distribution is used to model signal detection theory, which is concerned with the ability to differentiate between information-bearing patterns and random patterns that distract from the information.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Geometric Distribution\n",
      "- Negative Binomial Distribution\n",
      "- Hypergeometric Distribution\n",
      "- Poisson Distribution\n",
      "- Exponential Distribution\n",
      "- Gamma Distribution\n",
      "- Beta Distribution\n",
      "DONE GENERATING: bernoulli_distribution\n",
      "NOW GENERATING: binomial_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"binomial_distribution\": {\n",
      "        \"title\": \"Binomial Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"discrete_mathematics\", \"combinatorics\"],\n",
      "        \"further_readings\": [\"negative_binomial_distribution\", \"hypergeometric_distribution\", \"Poisson_distribution\", \"central_limit_theorem\", \"confidence_intervals\", \"hypothesis_testing\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Binomial Distribution\n",
      "\n",
      "The binomial distribution is a probability distribution that describes the number of successes in a fixed number of independent trials, where each trial has the same probability of success. It is a common distribution in statistics and is used to model a wide range of phenomena, from the number of heads obtained from flipping a coin a fixed number of times to the number of successful sales calls made by a telemarketer in a day.\n",
      "\n",
      "## Definition\n",
      "\n",
      "Suppose that an experiment consists of $n$ independent trials, where each trial results in a success with probability $p$ and a failure with probability $1-p$. Let $X$ be the random variable that represents the number of successes in these $n$ trials. Then $X$ follows a binomial distribution with parameters $n$ and $p$, denoted as $X \\sim \\text{Bin}(n,p)$, if the probability mass function of $X$ is given by:\n",
      "\n",
      "$$P(X=k) = {n \\choose k} p^k (1-p)^{n-k}, \\quad k=0,1,2,\\dots,n,$$\n",
      "\n",
      "where ${n \\choose k}=\\frac{n!}{k!(n-k)!}$ is the binomial coefficient.\n",
      "\n",
      "## Properties\n",
      "\n",
      "The binomial distribution has the following properties:\n",
      "\n",
      "- Mean: $\\mu = np$\n",
      "- Variance: $\\sigma^2 = np(1-p)$\n",
      "- Moment generating function: $M_X(t) = (pe^t + 1 - p)^n$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The binomial distribution is used in a variety of applications, such as:\n",
      "\n",
      "- Quality control: The number of defective items in a sample of fixed size from a production line can be modeled using a binomial distribution.\n",
      "- Elections: The number of votes obtained by a candidate in a fixed number of polling stations can be modeled using a binomial distribution.\n",
      "- Finance: The number of successful trades made by a trader in a fixed number of trading days can be modeled using a binomial distribution.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Negative binomial distribution: A generalization of the binomial distribution that allows for an arbitrary number of failures before a fixed number of successes is achieved.\n",
      "- Hypergeometric distribution: A distribution that models the number of successes in a fixed number of trials without replacement from a finite population of size $N$.\n",
      "- Poisson distribution: A distribution that models the number of rare events in a fixed interval of time or space.\n",
      "- Central limit theorem: A theorem that states that the sum of independent and identically distributed random variables tends to follow a normal distribution as the sample size increases, regardless of the underlying distribution of the variables.\n",
      "- Confidence intervals: A range of values around a sample statistic that is likely to contain the true population parameter with a given level of confidence.\n",
      "- Hypothesis testing: A statistical procedure for testing a hypothesis about a population parameter using a sample statistic.\n",
      "DONE GENERATING: binomial_distribution\n",
      "NOW GENERATING: poisson_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"poisson_distribution\": {\n",
      "        \"title\": \"Poisson Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"binomial_distribution\", \"expectation_and_variance\", \"exponential_distribution\"],\n",
      "        \"further_readings\": [\"negative_binomial_distribution\", \"geometric_distribution\", \"hypergeometric_distribution\", \"chi_squared_distribution\", \"normal_distribution\", \"central_limit_theorem\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Poisson Distribution\n",
      "\n",
      "The Poisson distribution is a probability distribution that describes the number of times an event occurs within a fixed interval of time or space, given that the events occur independently and at a constant rate. It is named after the French mathematician Siméon Denis Poisson, who introduced the distribution in 1837.\n",
      "\n",
      "## Probability Mass Function\n",
      "\n",
      "The probability mass function (PMF) of the Poisson distribution is given by:\n",
      "\n",
      "$$ P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\n",
      "\n",
      "where $X$ is the number of events, and $\\lambda$ is the average rate of events per interval. The PMF describes the probability of observing exactly $k$ events in the interval.\n",
      "\n",
      "## Mean and Variance\n",
      "\n",
      "The mean and variance of the Poisson distribution are both equal to $\\lambda$.\n",
      "\n",
      "$$ E(X) = \\lambda $$\n",
      "\n",
      "$$ Var(X) = \\lambda $$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Poisson distribution has many practical applications in various fields, such as:\n",
      "\n",
      "- Epidemiology: modeling the spread of diseases and infections\n",
      "- Finance: modeling the number of defaults or losses in a portfolio of loans or investments\n",
      "- Telecommunications: modeling the number of calls or messages in a given time period\n",
      "- Traffic engineering: modeling the number of vehicles or accidents in a given area or time period\n",
      "\n",
      "## Relation to Other Distributions\n",
      "\n",
      "The Poisson distribution is a limiting case of the binomial distribution, when the number of trials $n$ is large and the probability of success $p$ is small, such that $\\lambda = np$ is fixed.\n",
      "\n",
      "The Poisson distribution is also related to the exponential distribution, which describes the time between consecutive events in a Poisson process.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The Poisson distribution is a simple yet powerful tool for modeling the occurrence of rare or random events. Its properties and applications make it a fundamental concept in probability theory and statistics.\n",
      "DONE GENERATING: poisson_distribution\n",
      "NOW GENERATING: uniform_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"uniform_distribution\": {\n",
      "        \"title\": \"Uniform Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"random_variables\", \"cumulative_distribution_functions\"],\n",
      "        \"further_readings\": [\"normal_distribution\", \"exponential_distribution\", \"gamma_distribution\", \"chi_squared_distribution\", \"beta_distribution\", \"weibull_distribution\", \"lognormal_distribution\", \"pareto_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Uniform Distribution\n",
      "\n",
      "The **uniform distribution** is a continuous probability distribution in which all values within a given interval are equally likely to occur. This distribution is also known as the rectangular distribution due to its constant probability density function (PDF) over the interval.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the uniform distribution is defined as:\n",
      "\n",
      "$$\n",
      "f(x) =\n",
      "\\begin{cases}\n",
      "\\frac{1}{b-a}, & \\text{if } a \\leq x \\leq b \\\\\n",
      "0, & \\text{otherwise}\n",
      "\\end{cases}\n",
      "$$\n",
      "\n",
      "where $a$ and $b$ are the lower and upper bounds of the interval, respectively.\n",
      "\n",
      "## Cumulative Distribution Function\n",
      "\n",
      "The cumulative distribution function (CDF) of the uniform distribution is defined as:\n",
      "\n",
      "$$\n",
      "F(x) =\n",
      "\\begin{cases}\n",
      "0, & \\text{if } x < a \\\\\n",
      "\\frac{x-a}{b-a}, & \\text{if } a \\leq x \\leq b \\\\\n",
      "1, & \\text{if } x > b\n",
      "\\end{cases}\n",
      "$$\n",
      "\n",
      "## Mean and Variance\n",
      "\n",
      "The mean of the uniform distribution is:\n",
      "\n",
      "$$\n",
      "\\mu = \\frac{a+b}{2}\n",
      "$$\n",
      "\n",
      "and the variance is:\n",
      "\n",
      "$$\n",
      "\\sigma^2 = \\frac{(b-a)^2}{12}\n",
      "$$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The uniform distribution is commonly used in simulations, random number generation, and statistical modeling. It has applications in fields such as finance, physics, and engineering.\n",
      "\n",
      "For example, in finance, the uniform distribution can be used to model the price fluctuations of an asset within a given range. In physics, it can be used to model the distribution of particles within a given volume. In engineering, it can be used to model the tolerance of a manufactured product within a given range.\n",
      "\n",
      "Overall, the uniform distribution is a simple and useful probability distribution that is widely used in various fields.\n",
      "DONE GENERATING: uniform_distribution\n",
      "NOW GENERATING: normal_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"normal_distribution\": {\n",
      "        \"title\": \"Normal Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"central_limit_theorem\", \"standard_deviation\"],\n",
      "        \"further_readings\": [\"multivariate_normal_distribution\", \"t_distribution\", \"chi_square_distribution\", \"f_distribution\", \"normality_tests\", \"maximum_likelihood_estimation\", \"Bayesian_inference\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Normal Distribution\n",
      "\n",
      "The normal distribution, also known as the Gaussian distribution, is a continuous probability distribution that is widely used in statistics, science, engineering, and many other fields. It is a bell-shaped distribution that describes the behavior of many natural and human-made phenomena, such as the height and weight of people, the errors in measurements and observations, the scores in standardized tests, and the noise in communication channels.\n",
      "\n",
      "## Characteristics\n",
      "\n",
      "The normal distribution is characterized by two parameters: the mean $\\mu$ and the standard deviation $\\sigma$. The mean represents the center of the distribution, while the standard deviation represents the spread of the distribution. The probability density function (PDF) of the normal distribution is given by:\n",
      "\n",
      "$$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
      "\n",
      "where $x$ is a random variable, $\\mu$ is the mean, $\\sigma$ is the standard deviation, and $e$ is the base of the natural logarithm.\n",
      "\n",
      "The normal distribution has several important properties that make it a useful model for many applications. Some of these properties are:\n",
      "\n",
      "- The total area under the curve of the PDF is equal to 1, which means that the normal distribution is a valid probability distribution.\n",
      "\n",
      "- The normal distribution is symmetric about the mean, which means that the probability of getting a value above the mean is the same as the probability of getting a value below the mean.\n",
      "\n",
      "- The normal distribution is unimodal, which means that it has only one mode or peak.\n",
      "\n",
      "- The normal distribution has a finite range from $-\\infty$ to $+\\infty$, although its probability density becomes smaller and smaller as $x$ moves away from the mean.\n",
      "\n",
      "## Standard Normal Distribution\n",
      "\n",
      "The standard normal distribution is a special case of the normal distribution where the mean is 0 and the standard deviation is 1. It is denoted by $Z$ and has a probability density function given by:\n",
      "\n",
      "$$f(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{z^2}{2}}$$\n",
      "\n",
      "where $z$ is a standard normal variable.\n",
      "\n",
      "The standard normal distribution is important because it allows us to convert any normal distribution into a standard form using a process called standardization. Given a normal variable $X$ with mean $\\mu$ and standard deviation $\\sigma$, the standard normal variable $Z$ is defined as:\n",
      "\n",
      "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
      "\n",
      "The standardization formula gives us a way to calculate the probability of any normal variable by using the probabilities of the standard normal variable, which are tabulated in statistical tables or calculated using software.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The normal distribution has many applications in statistics, science, engineering, and finance. Some of the most common applications are:\n",
      "\n",
      "- Confidence intervals: The normal distribution is used to construct confidence intervals for population parameters, such as the mean and the proportion, based on sample statistics.\n",
      "\n",
      "- Hypothesis testing: The normal distribution is used to test hypotheses about population parameters, such as the difference between two means or the correlation between two variables, based on sample statistics.\n",
      "\n",
      "- Process control: The normal distribution is used to model and control manufacturing processes, such as the quality of products and the efficiency of machines, based on measurements and observations.\n",
      "\n",
      "- Risk management: The normal distribution is used to model and assess risks in finance and insurance, such as the returns of stocks and bonds, the losses of portfolios, and the premiums of policies, based on historical data and statistical models.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Multivariate Normal Distribution\n",
      "- Student's t-Distribution\n",
      "- Chi-Square Distribution\n",
      "- F-Distribution\n",
      "- Normality Tests\n",
      "- Maximum Likelihood Estimation\n",
      "- Bayesian Inference\n",
      "DONE GENERATING: normal_distribution\n",
      "NOW GENERATING: exponential_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"exponential_distribution\": {\n",
      "        \"title\": \"Exponential Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"random_variables\", \"expectation_and_variance\", \"derivative_rules\", \"integrals_and_limits\"],\n",
      "        \"further_readings\": [\"poisson_distribution\", \"gamma_distribution\", \"weibull_distribution\", \"normal_distribution\", \"chi_squared_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Exponential Distribution\n",
      "\n",
      "The exponential distribution is a probability distribution that describes the time between events in a Poisson process. It is a continuous distribution that has a single parameter, the rate parameter $\\lambda > 0$, which determines the expected value and variance of the distribution.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the exponential distribution is given by:\n",
      "\n",
      "$$f(x) = \\begin{cases} \\lambda e^{-\\lambda x}, & x \\geq 0 \\\\ 0, & x < 0 \\end{cases}$$\n",
      "\n",
      "where $x$ is a non-negative real number. The cumulative distribution function (CDF) of the exponential distribution is given by:\n",
      "\n",
      "$$F(x) = \\begin{cases} 1 - e^{-\\lambda x}, & x \\geq 0 \\\\ 0, & x < 0 \\end{cases}$$\n",
      "\n",
      "## Expected Value and Variance\n",
      "\n",
      "The expected value (or mean) of the exponential distribution is given by:\n",
      "\n",
      "$$E[X] = \\frac{1}{\\lambda}$$\n",
      "\n",
      "and the variance of the exponential distribution is given by:\n",
      "\n",
      "$$Var[X] = \\frac{1}{\\lambda^2}$$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The exponential distribution is commonly used in reliability engineering to model the time between failures of a system. It is also used in queuing theory to model the time between arrivals of customers in a queue. In addition, the exponential distribution is a key component in the Poisson process, which is used to model the occurrence of rare events over time.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Poisson Distribution\n",
      "- Gamma Distribution\n",
      "- Weibull Distribution\n",
      "- Normal Distribution\n",
      "- Chi-Squared Distribution\n",
      "DONE GENERATING: exponential_distribution\n",
      "NOW GENERATING: beta_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"beta_distribution\": {\n",
      "        \"title\": \"Beta Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"random_variables\", \"gamma_function\", \"conjugate_priors\", \"maximum_likelihood_estimation\"],\n",
      "        \"further_readings\": [\"dirichlet_distribution\", \"bayesian_inference\", \"markov_chain_monte_carlo\", \"variational_inference\", \"beta_regression\", \"beta_binomial_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Beta Distribution\n",
      "\n",
      "The Beta distribution is a continuous probability distribution that is defined on the interval [0,1]. It is a versatile distribution that is widely used in Bayesian statistics, machine learning, and deep learning. The Beta distribution is a conjugate prior to the Bernoulli and Binomial distributions, which means that its posterior distribution can be easily computed by multiplying it with the likelihood function of the data.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the Beta distribution is given by:\n",
      "\n",
      "$$ f(x|a,b) = \\frac{1}{B(a,b)} x^{a-1} (1-x)^{b-1} $$\n",
      "\n",
      "where x is a random variable between 0 and 1, and a and b are positive shape parameters. The Beta function B(a,b) is defined as:\n",
      "\n",
      "$$ B(a,b) = \\frac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a+b)} $$\n",
      "\n",
      "where the Gamma function is defined as:\n",
      "\n",
      "$$ \\Gamma(z) = \\int_0^{\\infty} t^{z-1} e^{-t} dt $$\n",
      "\n",
      "The Beta distribution is symmetric if a = b, and skewed if a ≠ b. The mean and variance of the Beta distribution are given by:\n",
      "\n",
      "$$ \\mu = \\frac{a}{a+b} $$\n",
      "\n",
      "$$ \\sigma^2 = \\frac{ab}{(a+b)^2(a+b+1)} $$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Beta distribution has many applications in statistics, machine learning, and deep learning. Some common applications include:\n",
      "\n",
      "- **Bayesian inference**: The Beta distribution is often used as a prior distribution for the probability of a binary event, such as flipping a coin or clicking on an ad. The posterior distribution can be easily computed using Bayes' theorem, and can be used to update the prior distribution with new data.\n",
      "\n",
      "- **A/B testing**: A/B testing is a common technique used in online marketing to compare the effectiveness of two different strategies, such as two different versions of a website. The Beta distribution can be used to model the probability of a user converting (e.g., making a purchase) under each strategy, and can be updated with new data to determine which strategy is more effective.\n",
      "\n",
      "- **Probabilistic programming**: Probabilistic programming is a powerful technique for building Bayesian models using programming languages such as Python or R. The Beta distribution is a fundamental building block of many probabilistic models, and is often used to model the prior distribution of a parameter.\n",
      "\n",
      "- **Reinforcement learning**: Reinforcement learning is a subfield of machine learning that is concerned with teaching agents to make decisions in an environment in order to maximize a reward signal. The Beta distribution can be used to model the probability of taking a particular action in a given state, and can be updated with new data to improve the agent's performance.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Dirichlet Distribution\n",
      "- Bayesian Inference\n",
      "- Markov Chain Monte Carlo\n",
      "- Variational Inference\n",
      "- Beta Regression\n",
      "- Beta-Binomial Distribution\n",
      "DONE GENERATING: beta_distribution\n",
      "NOW GENERATING: multivariate_distributions\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"multivariate_distributions\": {\n",
      "        \"title\": \"Multivariate Distributions\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"joint_probability_distribution\", \"marginal_probability_distribution\", \"conditional_probability_distribution\", \"covariance_and_correlation\", \"moment_generating_function\"],\n",
      "        \"further_readings\": [\"multivariate_normal_distribution\", \"copulas\", \"conditional_probability_distribution\", \"multivariate_regression\", \"multivariate_anova\", \"principal_component_analysis\", \"factor_analysis\", \"latent_dirichlet_allocation\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Multivariate Distributions\n",
      "\n",
      "Multivariate distributions are probability distributions that involve more than one random variable. They are used to model situations where the values of multiple variables are interdependent and may affect each other. In the context of artificial intelligence (AI), machine learning (ML), and deep learning (DL), multivariate distributions are often used to model complex data sets that have multiple variables.\n",
      "\n",
      "## Joint Probability Distribution\n",
      "\n",
      "The joint probability distribution of two or more random variables is a function that gives the probability of each possible combination of values for those variables. The joint probability distribution can be used to calculate the probability of any event involving the variables.\n",
      "\n",
      "## Marginal Probability Distribution\n",
      "\n",
      "The marginal probability distribution of a subset of random variables is obtained by summing or integrating the joint probability distribution over the remaining variables. This gives the probability distribution of the subset of variables without considering the others.\n",
      "\n",
      "## Conditional Probability Distribution\n",
      "\n",
      "The conditional probability distribution of a random variable given one or more other variables is a function that gives the probability of the first variable taking a particular value given that the other variable(s) take certain values.\n",
      "\n",
      "## Covariance and Correlation\n",
      "\n",
      "Covariance is a measure of the joint variability of two random variables. It measures how much the two variables change together. Correlation is a standardized measure of covariance, which is in the range of -1 to 1 and indicates the strength and direction of the linear relationship between the two variables.\n",
      "\n",
      "## Moment Generating Function\n",
      "\n",
      "The moment generating function of a multivariate distribution is a function that generates all the moments of the distribution. It is often used to calculate the mean, variance, and other moments of the distribution.\n",
      "\n",
      "## Multivariate Normal Distribution\n",
      "\n",
      "The multivariate normal distribution is a commonly used multivariate distribution that assumes that the variables are normally distributed and have a linear relationship. It is often used in statistical analysis and data modeling.\n",
      "\n",
      "## Copulas\n",
      "\n",
      "Copulas are functions that connect a multivariate distribution to its marginals. They are used to model the dependence structure between variables in a multivariate distribution.\n",
      "\n",
      "## Multivariate Regression\n",
      "\n",
      "Multivariate regression is a statistical technique used to model the relationship between multiple independent variables and a dependent variable. It is often used in predictive modeling and data analysis.\n",
      "\n",
      "## Multivariate ANOVA\n",
      "\n",
      "Multivariate analysis of variance (MANOVA) is a statistical technique used to analyze the differences between two or more groups of observations that have multiple dependent variables. It is often used in experimental design and data analysis.\n",
      "\n",
      "## Principal Component Analysis\n",
      "\n",
      "Principal component analysis (PCA) is a technique used to reduce the dimensionality of a multivariate data set. It is often used to identify the underlying structure of the data and to identify the most important variables.\n",
      "\n",
      "## Factor Analysis\n",
      "\n",
      "Factor analysis is a statistical technique used to identify the underlying factors that explain the correlation between multiple variables. It is often used in data analysis and model building.\n",
      "\n",
      "## Latent Dirichlet Allocation\n",
      "\n",
      "Latent Dirichlet Allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. It is often used in natural language processing and topic modeling.\n",
      "\n",
      "In summary, multivariate distributions are used to model complex data sets that have multiple variables. Joint probability distributions, marginal probability distributions, conditional probability distributions, covariance and correlation, moment generating functions, copulas, multivariate regression, multivariate ANOVA, principal component analysis, factor analysis, and latent Dirichlet allocation are all important concepts related to multivariate distributions in the context of artificial intelligence, machine learning, and deep learning.\n",
      "DONE GENERATING: multivariate_distributions\n",
      "NOW GENERATING: multinomial_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"multinomial_distribution\": {\n",
      "        \"title\": \"Multinomial Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"discrete_mathematics\"],\n",
      "        \"further_readings\": [\"binomial_distribution\", \"poisson_distribution\", \"beta_distribution\", \"dirichlet_distribution\", \"categorical_distribution\"],\n",
      "    }\n",
      "}\n",
      "\n",
      "# Multinomial Distribution\n",
      "\n",
      "The Multinomial Distribution is a probability distribution that describes the likelihood of observing a certain number of outcomes in a set of multiple discrete outcomes. It is a generalization of the binomial distribution, which describes the likelihood of observing a certain number of successes in a fixed number of trials.\n",
      "\n",
      "## Definition\n",
      "\n",
      "The Multinomial Distribution is defined as follows:\n",
      "\n",
      "Suppose there are $K$ possible outcomes, and an experiment is conducted $n$ times, where each trial can result in any of the $K$ outcomes. Let $p_1, p_2, ..., p_K$ be the probabilities of observing each of the $K$ outcomes on a single trial, and let $x_1, x_2, ..., x_K$ be the observed counts of each outcome over the $n$ trials. Then, the probability of observing the counts $x_1, x_2, ..., x_K$ is given by the Multinomial Distribution:\n",
      "\n",
      "$$P(X_1=x_1, X_2=x_2, ..., X_K=x_K) = {n \\choose x_1, x_2, ..., x_K}p_1^{x_1}p_2^{x_2}...p_K^{x_K}$$\n",
      "\n",
      "where ${n \\choose x_1, x_2, ..., x_K}$ is the multinomial coefficient:\n",
      "\n",
      "$${n \\choose x_1, x_2, ..., x_K} = \\frac{n!}{x_1!x_2!...x_K!}$$\n",
      "\n",
      "## Properties\n",
      "\n",
      "The Multinomial Distribution has several properties that are important to understand:\n",
      "\n",
      "- The mean and variance of the Multinomial Distribution are:\n",
      "\n",
      "$$E[X_i] = np_i$$\n",
      "\n",
      "$$Var[X_i] = np_i(1 - p_i)$$\n",
      "\n",
      "- The sum of the counts $x_1, x_2, ..., x_K$ is always equal to $n$.\n",
      "- The Multinomial Distribution is a discrete distribution, meaning that the possible outcomes are countable.\n",
      "- The Multinomial Distribution is a generalization of the binomial distribution, which describes the likelihood of observing a certain number of successes in a fixed number of trials with two possible outcomes.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Multinomial Distribution has several applications in machine learning and statistics:\n",
      "\n",
      "- In natural language processing, the Multinomial Distribution is often used to model the probability distribution over a set of words in a document.\n",
      "- In topic modeling, the Multinomial Distribution is used to model the probability distribution over a set of topics in a corpus of documents.\n",
      "- In clustering algorithms such as k-means, the Multinomial Distribution is often used to model the probability distribution over a set of discrete features.\n",
      "- In Bayesian statistics, the Multinomial Distribution is often used as a prior distribution for the parameters of a categorical distribution.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Binomial Distribution\n",
      "- Poisson Distribution\n",
      "- Beta Distribution\n",
      "- Dirichlet Distribution\n",
      "- Categorical Distribution\n",
      "DONE GENERATING: multinomial_distribution\n",
      "NOW GENERATING: multivariate_normal_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"multivariate_normal_distribution\": {\n",
      "        \"title\": \"Multivariate Normal Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"matrix_algebra\", \"linear_algebra\", \"calculus\", \"statistics\"],\n",
      "        \"further_readings\": [\"multivariate_analysis\", \"covariance_matrix\", \"principal_component_analysis\", \"canonical_correlation_analysis\", \"multivariate_regression_analysis\", \"factor_analysis\", \"discriminant_analysis\", \"bayesian_networks\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Multivariate Normal Distribution\n",
      "\n",
      "The **multivariate normal distribution** is a probability distribution that describes the probability distribution of a random vector in a multi-dimensional space. It is a generalization of the univariate normal distribution to higher dimensions. The multivariate normal distribution is also known as the multivariate Gaussian distribution because it is a multivariate version of the Gaussian distribution.\n",
      "\n",
      "## Definition\n",
      "\n",
      "A $p$-dimensional random vector $\\mathbf{X} = (X_1, X_2, \\ldots, X_p)^T$ follows a multivariate normal distribution, denoted by $\\mathbf{X} \\sim N_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, if its probability density function (PDF) is given by:\n",
      "\n",
      "$$f(\\mathbf{x}; \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{(2\\pi)^{\\frac{p}{2}}|\\boldsymbol{\\Sigma}|^{\\frac{1}{2}}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^T\\boldsymbol{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right)$$\n",
      "\n",
      "where $\\boldsymbol{\\mu}$ is a $p$-dimensional vector of mean values, and $\\boldsymbol{\\Sigma}$ is a $p \\times p$ positive definite symmetric matrix of covariance values.\n",
      "\n",
      "## Properties\n",
      "\n",
      "The multivariate normal distribution has several important properties:\n",
      "\n",
      "- The mean vector $\\boldsymbol{\\mu}$ determines the center of the distribution and the covariance matrix $\\boldsymbol{\\Sigma}$ determines the shape of the distribution.\n",
      "\n",
      "- The marginal distribution of any subset of components of a multivariate normal distribution is also normal.\n",
      "\n",
      "- Any linear combination of the components of a multivariate normal distribution is also normal.\n",
      "\n",
      "- The maximum likelihood estimator of the mean vector is the sample mean vector, and the maximum likelihood estimator of the covariance matrix is the sample covariance matrix.\n",
      "\n",
      "- If $\\mathbf{X} \\sim N_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, then the distribution of $\\mathbf{Y} = \\mathbf{AX} + \\mathbf{b}$, where $\\mathbf{A}$ is a $q \\times p$ matrix and $\\mathbf{b}$ is a $q$-dimensional vector, is also multivariate normal, with mean $\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}$ and covariance matrix $\\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T$.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The multivariate normal distribution has many applications in statistics, machine learning, and other fields. Some examples include:\n",
      "\n",
      "- In finance, the multivariate normal distribution is used to model the joint distribution of multiple stock prices or other financial variables.\n",
      "\n",
      "- In image processing, the multivariate normal distribution is used to model the joint distribution of pixel values in an image.\n",
      "\n",
      "- In machine learning, the multivariate normal distribution is often used as a prior distribution for Bayesian models or as a generative model for unsupervised learning.\n",
      "\n",
      "- In data analysis, the multivariate normal distribution is used in many multivariate techniques, such as principal component analysis, canonical correlation analysis, and discriminant analysis.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- **Multivariate Analysis**: This book by K.V. Mardia, J.T. Kent, and J.M. Bibby provides a comprehensive introduction to multivariate analysis, including the multivariate normal distribution.\n",
      "\n",
      "- **Covariance Matrix**: This Wikipedia page provides an overview of the covariance matrix, which is a key component of the multivariate normal distribution.\n",
      "\n",
      "- **Principal Component Analysis**: This Wikipedia page provides an overview of principal component analysis, which is a technique for reducing the dimensionality of multivariate data.\n",
      "\n",
      "- **Canonical Correlation Analysis**: This Wikipedia page provides an overview of canonical correlation analysis, which is a technique for finding linear combinations of variables that are maximally correlated across two datasets.\n",
      "\n",
      "- **Multivariate Regression Analysis**: This article by David J. Olive provides an introduction to multivariate regression analysis, which is a technique for modeling the relationship between multiple predictor variables and a response variable.\n",
      "\n",
      "- **Factor Analysis**: This Wikipedia page provides an overview of factor analysis, which is a technique for finding latent variables that underlie a set of observed variables.\n",
      "\n",
      "- **Discriminant Analysis**: This Wikipedia page provides an overview of discriminant analysis, which is a technique for finding linear combinations of variables that can be used to classify observations into different groups.\n",
      "\n",
      "- **Bayesian Networks**: This book by Nir Friedman and Daphne Koller provides a comprehensive introduction to Bayesian networks, which are graphical models that can be used to represent and reason about uncertain knowledge.\n",
      "DONE GENERATING: multivariate_normal_distribution\n",
      "NOW GENERATING: gamma_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"gamma_distribution\": {\n",
      "        \"title\": \"Gamma Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"exponential_distribution\", \"poisson_distribution\", \"beta_distribution\", \"moment_generating_functions\", \"maximum_likelihood_estimation\", \"bayesian_inference\", \"hypothesis_testing\"],\n",
      "        \"further_readings\": [\"chi_squared_distribution\", \"weibull_distribution\", \"log_normal_distribution\", \"dirichlet_distribution\", \"gamma_process\", \"probability_theory\", \"statistical_inference\", \"time_series_analysis\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Gamma Distribution\n",
      "\n",
      "The **gamma distribution** is a continuous probability distribution that models the time until a specified number of events occur in a Poisson process. It is also used to model the waiting time until a certain amount of continuous time has passed, among other things.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function of the gamma distribution with shape parameter $\\alpha$ and rate parameter $\\beta$ is given by:\n",
      "\n",
      "$$\n",
      "f(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}\n",
      "$$\n",
      "\n",
      "where $\\Gamma$ is the gamma function, defined as:\n",
      "\n",
      "$$\n",
      "\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1} e^{-t}dt\n",
      "$$\n",
      "\n",
      "The mean and variance of the gamma distribution are given by:\n",
      "\n",
      "$$\n",
      "\\text{E}[X] = \\frac{\\alpha}{\\beta}\n",
      "$$\n",
      "\n",
      "$$\n",
      "\\text{Var}[X] = \\frac{\\alpha}{\\beta^2}\n",
      "$$\n",
      "\n",
      "## Properties\n",
      "\n",
      "- The gamma distribution is a two-parameter family of distributions, where $\\alpha$ controls the shape and $\\beta$ controls the scale.\n",
      "- When the shape parameter $\\alpha$ is an integer, the gamma distribution reduces to the Erlang distribution, which models the time until a specified number of events occur in a Poisson process.\n",
      "- When the shape parameter $\\alpha = 1$, the gamma distribution reduces to the exponential distribution, which models the waiting time until a single event occurs in a Poisson process.\n",
      "- When the shape parameter $\\alpha$ is greater than one, the gamma distribution is skewed to the right.\n",
      "- When the shape parameter $\\alpha$ is less than one, the gamma distribution is skewed to the left.\n",
      "- The gamma distribution is a conjugate prior to the inverse scale parameter of the normal distribution in Bayesian inference.\n",
      "\n",
      "## Applications\n",
      "\n",
      "- In reliability engineering, the gamma distribution is used to model the time until a failure occurs.\n",
      "- In queuing theory, the gamma distribution is used to model the time between arrivals in a Poisson process.\n",
      "- In finance, the gamma distribution is used to model the distribution of stock prices.\n",
      "- In machine learning, the gamma distribution is used as a prior distribution for Bayesian regression models.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Chi-Squared Distribution\n",
      "- Weibull Distribution\n",
      "- Log-Normal Distribution\n",
      "- Dirichlet Distribution\n",
      "- Gamma Process\n",
      "- Probability Theory\n",
      "- Statistical Inference\n",
      "- Time Series Analysis\n",
      "DONE GENERATING: gamma_distribution\n",
      "NOW GENERATING: pareto_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"pareto_distribution\": {\n",
      "        \"title\": \"Pareto Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"continuous_random_variables\"],\n",
      "        \"further_readings\": [\"exponential_distribution\", \"normal_distribution\", \"gamma_distribution\", \"beta_distribution\"],\n",
      "    }\n",
      "}\n",
      "\n",
      "# Pareto Distribution\n",
      "\n",
      "The Pareto distribution is a continuous probability distribution that is used in various fields such as economics, finance, and engineering. It is named after Italian economist Vilfredo Pareto, who introduced the concept of Pareto efficiency in economics. \n",
      "\n",
      "## Definition\n",
      "\n",
      "The Pareto distribution is defined by its probability density function (PDF):\n",
      "\n",
      "$$\n",
      "f(x) = \\begin{cases}\n",
      "      \\frac{\\alpha k^\\alpha}{x^{\\alpha+1}}, & \\text{if}\\ x \\geq k \\\\\n",
      "      0, & \\text{otherwise}\n",
      "    \\end{cases}\n",
      "$$\n",
      "\n",
      "where $x$ is a random variable, $k$ is the minimum value of $x$, and $\\alpha$ is a shape parameter. The Pareto distribution is a power-law distribution, which means that its tail follows a power-law relationship.\n",
      "\n",
      "## Properties\n",
      "\n",
      "The Pareto distribution has several important properties:\n",
      "\n",
      "- **Heavy-tailed distribution:** The Pareto distribution has a heavy tail, which means that it has a higher probability of generating extreme values compared to other distributions such as the normal distribution.\n",
      "- **Unbounded distribution:** The Pareto distribution is an unbounded distribution, which means that it has no upper limit and can generate arbitrarily large values.\n",
      "- **Scale-free distribution:** The Pareto distribution is a scale-free distribution, which means that it does not change its shape when scaled by a constant factor. This property makes it useful in modeling phenomena that exhibit scale-free behavior, such as income distributions and city sizes.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Pareto distribution has several applications in various fields:\n",
      "\n",
      "- **Economics:** The Pareto distribution is used to model income and wealth distributions, where a small fraction of the population holds a large share of the wealth.\n",
      "- **Finance:** The Pareto distribution is used to model the distribution of financial returns, where extreme values can have a significant impact on the overall returns.\n",
      "- **Engineering:** The Pareto distribution is used in reliability engineering to model the distribution of failure times, where a small fraction of the components account for a large share of the failures.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Exponential distribution\n",
      "- Normal distribution\n",
      "- Gamma distribution\n",
      "- Beta distribution\n",
      "DONE GENERATING: pareto_distribution\n",
      "NOW GENERATING: dirichlet_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"dirichlet_distribution\": {\n",
      "        \"title\": \"Dirichlet Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"gamma_distribution\", \"beta_distribution\", \"multinomial_distribution\", \"bayesian_inference\", \"conjugate_priors\"],\n",
      "        \"further_readings\": [\"dirichlet_process\", \"dirichlet_multinomial_distribution\", \"latent_dirichlet_allocation\", \"hierarchical_dirichlet_process\", \"bayesian_nonparametrics\", \"bayesian_model_selection\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Dirichlet Distribution\n",
      "\n",
      "The Dirichlet distribution is a family of continuous probability distributions that are defined over the probability simplex, which is a high-dimensional space that represents all the possible probability distributions of a categorical variable. Dirichlet distributions are commonly used in Bayesian inference and machine learning to model the prior probability distribution over the parameters of a multinomial distribution.\n",
      "\n",
      "## Definition\n",
      "\n",
      "A Dirichlet distribution is parameterized by a vector $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_K)$ of $K$ positive shape parameters. The probability density function of a $K$-dimensional Dirichlet distribution is given by:\n",
      "\n",
      "$$\n",
      "\\text{Dir}(\\mathbf{x} | \\boldsymbol{\\alpha}) = \\frac{1}{B(\\boldsymbol{\\alpha})} \\prod_{i=1}^{K} x_i^{\\alpha_i - 1} \\quad \\text{for} \\quad 0 \\le x_i \\le 1, \\sum_{i=1}^{K} x_i = 1,\n",
      "$$\n",
      "\n",
      "where $\\mathbf{x} = (x_1, x_2, \\ldots, x_K)$ is a $K$-dimensional probability vector (i.e., $0 \\le x_i \\le 1$ and $\\sum_{i=1}^{K} x_i = 1$), and $B(\\boldsymbol{\\alpha})$ is the multivariate Beta function given by:\n",
      "\n",
      "$$\n",
      "B(\\boldsymbol{\\alpha}) = \\frac{\\prod_{i=1}^{K} \\Gamma(\\alpha_i)}{\\Gamma(\\sum_{i=1}^{K} \\alpha_i)},\n",
      "$$\n",
      "\n",
      "where $\\Gamma(\\cdot)$ is the gamma function.\n",
      "\n",
      "## Properties\n",
      "\n",
      "### Mean and Variance\n",
      "\n",
      "The expected value (mean) and covariance matrix of a Dirichlet distribution are given by:\n",
      "\n",
      "$$\n",
      "\\mathbb{E}[\\mathbf{x}] = \\frac{1}{\\sum_{i=1}^{K} \\alpha_i} (\\alpha_1, \\alpha_2, \\ldots, \\alpha_K),\n",
      "$$\n",
      "\n",
      "and\n",
      "\n",
      "$$\n",
      "\\text{Cov}[\\mathbf{x}] = \\frac{1}{(\\sum_{i=1}^{K} \\alpha_i)^2 (\\sum_{i=1}^{K} \\alpha_i + 1)} \\begin{bmatrix} \\alpha_1 (\\sum_{i=1}^{K} \\alpha_i - \\alpha_1) & -\\alpha_1 \\alpha_2 & \\cdots & -\\alpha_1 \\alpha_K \\\\ -\\alpha_2 \\alpha_1 & \\alpha_2 (\\sum_{i=1}^{K} \\alpha_i - \\alpha_2) & \\cdots & -\\alpha_2 \\alpha_K \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ -\\alpha_K \\alpha_1 & -\\alpha_K \\alpha_2 & \\cdots & \\alpha_K (\\sum_{i=1}^{K} \\alpha_i - \\alpha_K) \\end{bmatrix},\n",
      "$$\n",
      "\n",
      "respectively.\n",
      "\n",
      "### Conjugacy\n",
      "\n",
      "The Dirichlet distribution is a conjugate prior of the multinomial distribution. This means that if the prior distribution over the parameters of a multinomial distribution is a Dirichlet distribution, then the posterior distribution is also a Dirichlet distribution. This property makes the Dirichlet distribution a popular choice for Bayesian inference with multinomial data.\n",
      "\n",
      "### Marginal and Conditional Distributions\n",
      "\n",
      "The marginal distribution over any subset of the components of a Dirichlet-distributed random vector is also a Dirichlet distribution. Moreover, the conditional distribution of any component of a Dirichlet-distributed random vector given the values of the other components is also a Dirichlet distribution.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Dirichlet distribution has many applications in machine learning and Bayesian inference, including:\n",
      "\n",
      "- **Topic modeling**: Latent Dirichlet Allocation (LDA) is a generative probabilistic model that uses a Dirichlet prior over the topic probabilities of each document and a multinomial likelihood to model the word frequencies in each document.\n",
      "- **Clustering**: The Dirichlet Process is a nonparametric Bayesian clustering method that uses a Dirichlet process prior to model the distribution over the number of clusters and the distribution of points within each cluster.\n",
      "- **Natural language processing**: The Dirichlet-multinomial distribution is a generalization of the multinomial distribution that uses a Dirichlet prior over the parameters of the multinomial distribution to model the frequency distribution of words in a document.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Dirichlet Process\n",
      "- Dirichlet-multinomial Distribution\n",
      "- Latent Dirichlet Allocation\n",
      "- Hierarchical Dirichlet Process\n",
      "- Bayesian Nonparametrics\n",
      "- Bayesian Model Selection\n",
      "DONE GENERATING: dirichlet_distribution\n",
      "NOW GENERATING: weibull_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"weibull_distribution\": {\n",
      "        \"title\": \"Weibull Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"exponential_distribution\", \"hazard_functions\", \"maximum_likelihood_estimation\", \"survival_analysis\"],\n",
      "        \"further_readings\": [\"gamma_distribution\", \"lognormal_distribution\", \"pareto_distribution\", \"extreme_value_distribution\", \"reliability_engineering\", \"accelerated_life_testing\", \"censoring_and_truncation\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Weibull Distribution\n",
      "\n",
      "The Weibull distribution is a continuous probability distribution that is widely used in reliability engineering to model the lifetime of mechanical and electrical components. It is named after Swedish mathematician Waloddi Weibull, who first proposed the distribution in 1937 to describe the breaking strength of materials.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the Weibull distribution is given by:\n",
      "\n",
      "$$f(x;k,\\lambda)=\\begin{cases}\n",
      "\\frac{k}{\\lambda}\\left(\\frac{x}{\\lambda}\\right)^{k-1}e^{-(x/\\lambda)^k}, & x\\geq 0\\\\\n",
      "0, & x<0\n",
      "\\end{cases}$$\n",
      "\n",
      "where $x$ is the random variable, $k$ is the shape parameter, and $\\lambda$ is the scale parameter.\n",
      "\n",
      "The shape parameter $k$ determines the shape of the PDF. If $k>1$, the PDF is bell-shaped and the distribution is said to be \"Weibull in shape\". If $k=1$, the PDF is exponential and the distribution reduces to the exponential distribution. If $k<1$, the PDF is U-shaped and the distribution is said to be \"reverse Weibull in shape\".\n",
      "\n",
      "The scale parameter $\\lambda$ determines the scale of the PDF. It represents the characteristic lifetime of the component. The larger the value of $\\lambda$, the longer the expected lifetime of the component.\n",
      "\n",
      "## Cumulative Distribution Function\n",
      "\n",
      "The cumulative distribution function (CDF) of the Weibull distribution is given by:\n",
      "\n",
      "$$F(x;k,\\lambda)=1-e^{-(x/\\lambda)^k}$$\n",
      "\n",
      "The CDF gives the probability that the random variable $x$ is less than or equal to a certain value $x_0$. It can be used to calculate the reliability function, which gives the probability that the component will survive beyond a certain time $t$:\n",
      "\n",
      "$$R(t;k,\\lambda)=1-F(t;k,\\lambda)=e^{-(t/\\lambda)^k}$$\n",
      "\n",
      "## Hazard Function\n",
      "\n",
      "The hazard function of the Weibull distribution is given by:\n",
      "\n",
      "$$h(x;k,\\lambda)=\\frac{f(x;k,\\lambda)}{R(x;k,\\lambda)}=\\frac{k}{\\lambda}\\left(\\frac{x}{\\lambda}\\right)^{k-1}$$\n",
      "\n",
      "The hazard function gives the instantaneous failure rate at time $t$ given that the component has survived up to that time. It is an increasing function of time for $k>1$ (increasing failure rate) and a decreasing function of time for $k<1$ (decreasing failure rate).\n",
      "\n",
      "## Maximum Likelihood Estimation\n",
      "\n",
      "Given a sample of $n$ observations $x_1,x_2,\\ldots,x_n$ from a Weibull distribution, the maximum likelihood estimator (MLE) of the parameters $k$ and $\\lambda$ is obtained by maximizing the log-likelihood function:\n",
      "\n",
      "$$\\ln L=\\sum_{i=1}^n\\ln f(x_i;k,\\lambda)=n\\ln\\frac{k}{\\lambda}+(k-1)\\sum_{i=1}^n\\ln\\frac{x_i}{\\lambda}-\\sum_{i=1}^n\\left(\\frac{x_i}{\\lambda}\\right)^k$$\n",
      "\n",
      "The MLEs of $k$ and $\\lambda$ are the solutions of the following equations:\n",
      "\n",
      "$$\\frac{\\partial\\ln L}{\\partial k}=\\frac{n}{k}-\\sum_{i=1}^n\\ln\\frac{x_i}{\\lambda}+\\sum_{i=1}^n\\left(\\frac{x_i}{\\lambda}\\right)^k\\ln\\frac{x_i}{\\lambda}=0$$\n",
      "\n",
      "$$\\frac{\\partial\\ln L}{\\partial\\lambda}=-\\frac{n}{\\lambda}+\\frac{k}{\\lambda}\\sum_{i=1}^n\\left(\\frac{x_i}{\\lambda}\\right)^k=0$$\n",
      "\n",
      "These equations can be solved numerically using iterative methods.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Weibull distribution is widely used in reliability engineering to model the lifetime of mechanical and electrical components. It can also be used to model the time-to-failure of software systems and the duration of human lifetimes.\n",
      "\n",
      "In survival analysis, the Weibull distribution is often used to model the hazard function of a population. It is also used in accelerated life testing, where the goal is to estimate the lifetime distribution of a component under accelerated conditions.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Gamma Distribution\n",
      "- Lognormal Distribution\n",
      "- Pareto Distribution\n",
      "- Extreme Value Distribution\n",
      "- Reliability Engineering\n",
      "- Accelerated Life Testing\n",
      "- Censoring and Truncation.\n",
      "DONE GENERATING: weibull_distribution\n",
      "NOW GENERATING: student_t_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"student_t_distribution\": {\n",
      "        \"title\": \"Student T Distribution\",\n",
      "        \"prerequisites\": [\"normal_distribution\", \"hypothesis_testing\", \"confidence_intervals\", \"random_variables\", \"probability_distributions\"],\n",
      "        \"further_readings\": [\"central_limit_theorem\", \"regression_analysis\", \"bayesian_inference\", \"statistical_learning_theory\", \"time_series_analysis\"],\n",
      "    }\n",
      "}\n",
      "\n",
      "# Student T Distribution\n",
      "\n",
      "The Student T Distribution, also known as the t-distribution, is a probability distribution used in statistical inference to estimate the mean of a normally distributed population when the sample size is small or the population's standard deviation is unknown.\n",
      "\n",
      "The t-distribution is similar to the normal distribution but with heavier tails, which means it has more probability in the tails and less in the center. This is because the t-distribution takes into account the uncertainty introduced by the sample size and the estimation of the population standard deviation.\n",
      "\n",
      "The t-distribution is characterized by its degrees of freedom (df), which is the number of observations minus one. As the sample size increases, the t-distribution approaches the normal distribution.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the t-distribution with df degrees of freedom is given by:\n",
      "\n",
      "$$ f(t) = \\frac{\\Gamma(\\frac{df+1}{2})}{\\sqrt{df\\pi}\\Gamma(\\frac{df}{2})}\\Big(1+\\frac{t^2}{df}\\Big)^{-\\frac{df+1}{2}} $$\n",
      "\n",
      "where $\\Gamma(\\cdot)$ is the gamma function.\n",
      "\n",
      "## Confidence Intervals and Hypothesis Testing\n",
      "\n",
      "The t-distribution is commonly used to calculate confidence intervals and perform hypothesis testing for the mean of a normally distributed population when the sample size is small or the population's standard deviation is unknown. \n",
      "\n",
      "A confidence interval is a range of values that is likely to contain the true population mean with a certain level of confidence. The level of confidence is determined by the chosen significance level and the degrees of freedom of the t-distribution.\n",
      "\n",
      "Hypothesis testing involves making a decision about a population parameter based on a sample statistic. The null hypothesis is usually that the population mean is equal to a certain value, and the alternate hypothesis is that it is not. The t-statistic is calculated based on the sample data and compared to the critical values of the t-distribution to determine whether to reject or fail to reject the null hypothesis.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The t-distribution is commonly used in various fields such as finance, economics, engineering, and medicine. Some examples include:\n",
      "\n",
      "- Estimating the mean return of a portfolio based on a small sample of returns\n",
      "- Determining whether a new drug has a significant effect on a health condition based on a small sample of patients\n",
      "- Estimating the average weight of a certain species of animal based on a small sample of specimens\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Central Limit Theorem\n",
      "- Regression Analysis\n",
      "- Bayesian Inference\n",
      "- Statistical Learning Theory\n",
      "- Time Series Analysis\n",
      "DONE GENERATING: student_t_distribution\n",
      "NOW GENERATING: chi_square_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"chi_square_distribution\": {\n",
      "        \"title\": \"Chi Square Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"hypothesis_testing\", \"normal_distribution\"],\n",
      "        \"further_readings\": [\"student_t_distribution\", \"f_distribution\", \"central_limit_theorem\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Chi Square Distribution\n",
      "\n",
      "The Chi Square distribution is a probability distribution that is widely used in statistical inference for hypothesis testing. It is characterized by a single parameter, the degrees of freedom, which determines its shape. \n",
      "\n",
      "## Definition\n",
      "\n",
      "The Chi Square distribution is the distribution of the sum of the squares of independent standard normal random variables. Let $Z_1, Z_2, \\dots, Z_k$ be independent standard normal random variables, then the sum of their squares $Q = \\sum_{i=1}^k Z_i^2$ follows a Chi Square distribution with $k$ degrees of freedom, denoted as $Q\\sim\\chi^2(k)$.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the Chi Square distribution with $k$ degrees of freedom is given by:\n",
      "\n",
      "$$f(x;k) = \\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}e^{-x/2}, \\quad x > 0$$\n",
      "\n",
      "where $\\Gamma(\\cdot)$ is the gamma function.\n",
      "\n",
      "## Properties\n",
      "\n",
      "1. Expectation and Variance:\n",
      "\n",
      "The expected value and variance of a Chi Square distribution with $k$ degrees of freedom are:\n",
      "\n",
      "$$\\mathrm{E}[X] = k$$\n",
      "\n",
      "$$\\mathrm{Var}[X] = 2k$$\n",
      "\n",
      "2. Moments:\n",
      "\n",
      "The $r$-th moment of a Chi Square distribution with $k$ degrees of freedom is given by:\n",
      "\n",
      "$$\\mathrm{E}[X^r] = \\frac{(2r)!!}{2^rr!}k^r$$\n",
      "\n",
      "where $(2r)!!$ is the double factorial.\n",
      "\n",
      "3. Central Limit Theorem:\n",
      "\n",
      "The Chi Square distribution arises as a special case of the central limit theorem. Specifically, if $X_1, X_2, \\dots, X_n$ are independent and identically distributed random variables with mean $\\mu$ and variance $\\sigma^2$, then the distribution of the standardized sum of squares $\\frac{\\sum_{i=1}^n(X_i-\\mu)^2}{\\sigma^2}$ converges to a Chi Square distribution with $n$ degrees of freedom as $n$ approaches infinity.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Chi Square distribution has many applications in statistical inference. Some of the key applications are:\n",
      "\n",
      "1. Hypothesis Testing:\n",
      "\n",
      "The Chi Square distribution is used to test hypotheses about the variances of normal populations, as well as to test for independence in contingency tables.\n",
      "\n",
      "2. Goodness of Fit Tests:\n",
      "\n",
      "The Chi Square distribution is used in goodness of fit tests to determine whether a set of observed data is consistent with a specific theoretical distribution.\n",
      "\n",
      "3. Confidence Intervals:\n",
      "\n",
      "The Chi Square distribution is used to construct confidence intervals for the variances of normal populations.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Student's t Distribution\n",
      "- F Distribution\n",
      "- Central Limit Theorem.\n",
      "DONE GENERATING: chi_square_distribution\n",
      "NOW GENERATING: f_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"f_distribution\": {\n",
      "        \"title\": \"F Distribution\",\n",
      "        \"prerequisites\": [\"normal_distribution\", \"chi_squared_distribution\", \"hypothesis_testing\", \"analysis_of_variance\", \"regression_analysis\"],\n",
      "        \"further_readings\": [\"probability_distributions\", \"confidence_intervals\", \"t_distribution\", \"central_limit_theorem\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# F Distribution\n",
      "\n",
      "The F distribution is a probability distribution that arises in hypothesis testing, particularly in the comparison of variances of two or more populations. It is characterized by two parameters, the degrees of freedom of the numerator and the degrees of freedom of the denominator. The F distribution is a continuous probability distribution with a range of values between 0 and positive infinity.\n",
      "\n",
      "## Probability Density Function\n",
      "\n",
      "The probability density function (PDF) of the F distribution is given by:\n",
      "\n",
      "$$ f(x; d_1, d_2) = \\frac{\\sqrt{\\frac{(d_1 x)^{d_1} d_2^{d_2}}{(d_1 x + d_2)^{d_1+d_2}}}}{x B(\\frac{d_1}{2}, \\frac{d_2}{2})}, \\quad x > 0 $$\n",
      "\n",
      "where $d_1$ and $d_2$ are the degrees of freedom of the numerator and denominator, respectively, and $B(\\frac{d_1}{2}, \\frac{d_2}{2})$ is the beta function.\n",
      "\n",
      "## Properties\n",
      "\n",
      "Some of the key properties of the F distribution are:\n",
      "\n",
      "- The F distribution is a non-negative continuous probability distribution.\n",
      "- The mean of the F distribution is $\\frac{d_2}{d_2-2}$ for $d_2 > 2$.\n",
      "- The variance of the F distribution is $\\frac{2d_2^2(d_1+d_2-2)}{d_1(d_2-2)^2(d_2-4)}$ for $d_2 > 4$.\n",
      "- The F distribution is skewed to the right.\n",
      "- The F distribution is unimodal for $d_1 > 2$.\n",
      "\n",
      "## Application in Hypothesis Testing\n",
      "\n",
      "The F distribution is commonly used in hypothesis testing, particularly in the comparison of variances of two or more populations. The F statistic is calculated as the ratio of the sample variances of the populations being compared. The F distribution is then used to determine the p-value of the test, which is compared to the level of significance to determine if the null hypothesis should be rejected.\n",
      "\n",
      "## Related Topics\n",
      "\n",
      "- **Normal Distribution:** The F distribution is related to the chi-squared distribution, which is in turn related to the normal distribution.\n",
      "- **Chi-Squared Distribution:** The F distribution is a ratio of two chi-squared distributions.\n",
      "- **Hypothesis Testing:** The F distribution is commonly used in hypothesis testing to compare variances of populations.\n",
      "- **Analysis of Variance:** The F distribution is used in analysis of variance (ANOVA) to compare the means of multiple populations.\n",
      "- **Regression Analysis:** The F distribution is used in regression analysis to test the overall significance of the regression model.\n",
      "DONE GENERATING: f_distribution\n",
      "NOW GENERATING: cauchy_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"cauchy_distribution\": {\n",
      "        \"title\": \"Cauchy Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"central_limit_theorem\"],\n",
      "        \"further_readings\": [\"levy_distribution\", \"student_t_distribution\", \"heavy_tailed_distributions\"],\n",
      "    }\n",
      "}\n",
      "\n",
      "# Cauchy Distribution\n",
      "\n",
      "The Cauchy distribution is a continuous probability distribution that is frequently used in fields such as physics, engineering, and statistics. It is named after the French mathematician Augustin-Louis Cauchy, who first studied it in the early 19th century. The Cauchy distribution is also known as the Lorentz distribution, after the Dutch physicist Hendrik Lorentz.\n",
      "\n",
      "## Definition\n",
      "\n",
      "The Cauchy distribution is defined by its probability density function (PDF):\n",
      "\n",
      "$$ f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma [1 + (\\frac{x-x_0}{\\gamma})^2]} $$\n",
      "\n",
      "where $x_0$ is the location parameter (the median of the distribution), and $\\gamma$ is the scale parameter (the half-width at half-maximum).\n",
      "\n",
      "## Properties\n",
      "\n",
      "The Cauchy distribution has several notable properties:\n",
      "\n",
      "- It has no mean or variance, as the moments do not exist. This is due to the heavy tails of the distribution, which cause the integrals to diverge.\n",
      "- It is symmetric around the median $x_0$, meaning that the probability of observing a value to the left or right of $x_0$ is the same.\n",
      "- It has long tails, meaning that extreme values are more likely to occur than in other distributions with finite variance. This can cause problems in statistical inference, as the sample mean and variance may not converge to the population mean and variance.\n",
      "- It is a stable distribution, meaning that the sum of independent Cauchy-distributed random variables is also Cauchy-distributed.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Cauchy distribution has several applications in physics and engineering. It is used to model the resonance behavior of systems with damping, such as the motion of a pendulum or a mass-spring system. It is also used to model the distribution of velocities of particles in a gas or liquid, as well as the distribution of spacings between atoms in a crystal lattice.\n",
      "\n",
      "In statistics, the Cauchy distribution is sometimes used as a prior distribution in Bayesian inference, due to its heavy tails and symmetry. However, it is generally not recommended for this purpose, as it can lead to improper posteriors if the data is not Cauchy-distributed.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- The Levy distribution, which is a generalization of the Cauchy distribution.\n",
      "- The Student's t-distribution, which is similar to the Cauchy distribution but has finite variance.\n",
      "- Heavy-tailed distributions, which are distributions with tails that decay slower than an exponential function.\n",
      "DONE GENERATING: cauchy_distribution\n",
      "NOW GENERATING: copulas\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"copulas\": {\n",
      "        \"title\": \"Copulas\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"multivariate_statistics\", \"correlation_analysis\", \"maximum_likelihood_estimation\", \"statistics_of_extremes\"],\n",
      "        \"further_readings\": [\"dependence_modeling\", \"vine_copulas\", \"archimedean_copulas\", \"copula_regression\", \"copula_garch_models\", \"copula-based_time_series_analysis\", \"copula_networks\", \"copula-based_machine_learning_methods\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Copulas\n",
      "\n",
      "Copulas are a powerful tool in statistics that allow the modeling of complex dependencies between variables. Essentially, a copula is a function that links univariate distributions of each variable to their multivariate distribution. Copulas have been used in various fields, including finance, engineering, and environmental science.\n",
      "\n",
      "## Definition\n",
      "\n",
      "A copula is a multivariate probability distribution function that links marginal distributions of each variable to their joint distribution. A copula is denoted as $C(u_1,u_2,\\ldots,u_n)$ where $u_i$ is the cumulative distribution function of the $i$-th variable.\n",
      "\n",
      "To put it simply, a copula allows the modeling of the dependence structure between variables, irrespective of their marginal distributions. Copulas can be used to model various types of dependence, including linear and nonlinear, symmetric and asymmetric, and positive and negative.\n",
      "\n",
      "## Types of Copulas\n",
      "\n",
      "There are various types of copulas, including:\n",
      "\n",
      "- **Gaussian Copula**: Assumes that the marginal distributions are normal and the correlation matrix is constant.\n",
      "- **Archimedean Copulas**: Based on the use of an Archimedean generator function and can model various types of dependence.\n",
      "- **t-Copula**: Assumes that the marginal distributions are Student's t-distributions.\n",
      "- **Clayton Copula**: Suitable for modeling positive dependence.\n",
      "- **Gumbel Copula**: Suitable for modeling extreme dependence.\n",
      "- **Frank Copula**: Suitable for modeling asymmetric dependence.\n",
      "\n",
      "## Applications\n",
      "\n",
      "Copulas have a wide range of applications, including:\n",
      "\n",
      "- **Finance**: Copulas are widely used in finance to model the dependence structure between assets. They can be used to model joint distributions of stock prices, interest rates, and credit risk.\n",
      "- **Engineering**: Copulas can be used in engineering to model the dependence between variables such as load and strength. They can be used to model the joint distribution of wind speed and wind turbine output.\n",
      "- **Environmental Science**: Copulas can be used in environmental science to model the dependence between variables such as rainfall and flood levels. They can be used to model the joint distribution of temperature and precipitation.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Copulas are a powerful tool in statistics that allow the modeling of complex dependencies between variables. They have been used in various fields, including finance, engineering, and environmental science. Copulas can be used to model various types of dependence, including linear and nonlinear, symmetric and asymmetric, and positive and negative.\n",
      "DONE GENERATING: copulas\n",
      "NOW GENERATING: negative_binomial_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"negative_binomial_distribution\": {\n",
      "        \"title\": \"Negative Binomial Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"binomial_distribution\", \"poisson_distribution\", \"moment_generating_functions\", \"factorial_moments\", \"conditional_probability\"],\n",
      "        \"further_readings\": [\"zero_inflated_negative_binomial_distribution\", \"hurdle_negative_binomial_distribution\", \"geometric_distribution\", \"hypergeometric_distribution\", \"beta_negative_binomial_distribution\", \"bayesian_inference\", \"maximum_likelihood_estimation\", \"glm_models\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Negative Binomial Distribution\n",
      "\n",
      "The **Negative Binomial Distribution** is a probability distribution that models the number of failures in a sequence of independent and identically distributed Bernoulli trials before a specified number of successes is reached. It is a generalization of the **Binomial Distribution** in which the number of trials is not fixed, but rather the distribution continues until a specific number of successes is achieved.\n",
      "\n",
      "## Definition\n",
      "\n",
      "A random variable X has a **Negative Binomial Distribution** with parameters r and p if its probability mass function (PMF) is given by:\n",
      "\n",
      "$$P(X=k) = \\binom{k+r-1}{k}(1-p)^rp^k, \\quad k=0,1,2,\\dots$$\n",
      "\n",
      "where $r \\in \\mathbb{N}_0$ is the number of failures before the desired number of successes is reached, $p \\in (0,1)$ is the probability of success in each trial, and $\\binom{n}{k}$ is the binomial coefficient.\n",
      "\n",
      "## Mean and Variance\n",
      "\n",
      "The mean and variance of X are given by:\n",
      "\n",
      "$$\\mu = \\frac{r(1-p)}{p}$$\n",
      "\n",
      "$$\\sigma^2 = \\frac{r(1-p)}{p^2}$$\n",
      "\n",
      "## Moment Generating Function\n",
      "\n",
      "The **Moment Generating Function** (MGF) of X is given by:\n",
      "\n",
      "$$M_X(t) = \\left(\\frac{pe^t}{1-(1-p)e^t}\\right)^r$$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Negative Binomial Distribution is commonly used in a variety of fields, including:\n",
      "\n",
      "- Insurance: modeling the number of claims until a certain limit is reached\n",
      "- Biology: modeling the number of offspring until a certain number of successful births occurs\n",
      "- Sports: modeling the number of games until a team wins a certain number of games\n",
      "- Finance: modeling the number of trades until a certain profit level is reached\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- **Zero-Inflated Negative Binomial Distribution**: a variation of the Negative Binomial Distribution that allows for an excess of zero observations\n",
      "- **Hurdle Negative Binomial Distribution**: a variation of the Negative Binomial Distribution that models data with a large proportion of zeros\n",
      "- **Geometric Distribution**: a discrete probability distribution that models the number of trials needed to achieve the first success\n",
      "- **Hypergeometric Distribution**: a discrete probability distribution that models the probability of k successes in n draws without replacement from a finite population of size N that contains K successes\n",
      "- **Beta Negative Binomial Distribution**: a variation of the Negative Binomial Distribution that uses a beta distribution to model the probability of success\n",
      "- **Bayesian Inference**: a statistical framework that uses Bayes' theorem to update the probability of a hypothesis as new evidence becomes available\n",
      "- **Maximum Likelihood Estimation**: a method for estimating the parameters of a statistical model by maximizing the likelihood function\n",
      "- **GLM Models**: Generalized Linear Models that allow for the specification of a variety of distribution families, including the Negative Binomial Distribution.\n",
      "DONE GENERATING: negative_binomial_distribution\n",
      "NOW GENERATING: geometric_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"geometric_distribution\": {\n",
      "        \"title\": \"Geometric Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"binomial_distribution\", \"expected_value\", \"variance\", \"random_variables\"],\n",
      "        \"further_readings\": [\"negative_binomial_distribution\", \"poisson_distribution\", \"exponential_distribution\", \"weibull_distribution\", \"gamma_distribution\", \"beta_distribution\", \"chi_squared_distribution\", \"normal_distribution\", \"lognormal_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Geometric Distribution\n",
      "\n",
      "The geometric distribution is a probability distribution that models the number of trials required to obtain the first success in a sequence of independent Bernoulli trials, where each trial has the same probability of success.\n",
      "\n",
      "## Definition\n",
      "\n",
      "Let X be a random variable representing the number of trials required to obtain the first success in a sequence of independent Bernoulli trials, where p is the probability of success on each trial. Then X follows a geometric distribution with parameter p, denoted as X ~ Geometric(p).\n",
      "\n",
      "The probability mass function (PMF) of X is given by:\n",
      "\n",
      "$$P(X=k) = (1-p)^{k-1}p, \\text{ for } k=1,2,3,...$$\n",
      "\n",
      "The mean and variance of X are given by:\n",
      "\n",
      "$$\\mu = \\frac{1}{p}$$\n",
      "\n",
      "$$\\sigma^2 = \\frac{1-p}{p^2}$$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The geometric distribution has various applications in real-world scenarios where the probability of success is constant and the trials are independent. For example:\n",
      "\n",
      "- In finance, the geometric distribution can be used to model the number of trades required to obtain the first profitable trade in a sequence of independent trades, where each trade has the same probability of being profitable.\n",
      "- In computer science, the geometric distribution can be used to model the number of unsuccessful attempts required to find the first successful search result on a search engine, where each attempt has the same probability of returning a successful result.\n",
      "- In biology, the geometric distribution can be used to model the number of DNA sequencing reads required to obtain the first read that matches a given reference sequence, where each read has the same probability of matching the reference sequence.\n",
      "\n",
      "## Properties\n",
      "\n",
      "- The geometric distribution is memoryless, meaning that the conditional probability of obtaining the first success on the k+1-th trial given that the first k trials were failures is equal to the unconditional probability of obtaining the first success on the first trial. Formally, P(X=k+j | X>k) = P(X=j), for all k,j >= 1.\n",
      "- The geometric distribution is a special case of the negative binomial distribution with r=1, where r is the number of successes required.\n",
      "- The geometric distribution is right-skewed, meaning that it has a longer tail on the right side. Its mode is 1, and its median is ceil(log(0.5)/log(1-p)), which is the smallest integer greater than or equal to the logarithm base 1-p of 0.5.\n",
      "\n",
      "## Further Readings\n",
      "\n",
      "- Negative Binomial Distribution\n",
      "- Poisson Distribution\n",
      "- Exponential Distribution\n",
      "- Weibull Distribution\n",
      "- Gamma Distribution\n",
      "- Beta Distribution\n",
      "- Chi-Squared Distribution\n",
      "- Normal Distribution\n",
      "- Lognormal Distribution\n",
      "DONE GENERATING: geometric_distribution\n",
      "NOW GENERATING: hypergeometric_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"hypergeometric_distribution\": {\n",
      "        \"title\": \"Hypergeometric Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"combinatorics\"],\n",
      "        \"further_readings\": [\"binomial_distribution\", \"multinomial_distribution\", \"Poisson_distribution\", \"negative_binomial_distribution\", \"geometric_distribution\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Hypergeometric Distribution\n",
      "\n",
      "The hypergeometric distribution is a discrete probability distribution that describes the probability of having k successes in a sample of size n drawn without replacement from a finite population of size N that contains exactly K successes.\n",
      "\n",
      "The probability mass function of the hypergeometric distribution is given by:\n",
      "\n",
      "$$ P(X=k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}} $$\n",
      "\n",
      "where X is the random variable denoting the number of successes in the sample of size n, K is the number of successes in the population, N is the population size, and n is the sample size.\n",
      "\n",
      "The hypergeometric distribution is used in situations where the sampling is done without replacement, such as in quality control, where a batch of items is inspected and a sample is selected without returning the items to the batch. It is also used in genetics, where the distribution can be used to model the probability of observing a certain number of heterozygous individuals in a population.\n",
      "\n",
      "## Properties\n",
      "\n",
      "The mean and variance of the hypergeometric distribution are given by:\n",
      "\n",
      "$$ \\mu = \\frac{nK}{N} $$\n",
      "\n",
      "$$ \\sigma^2 = n\\frac{K}{N}\\left(1-\\frac{K}{N}\\right)\\frac{N-n}{N-1} $$\n",
      "\n",
      "## Relationship with Other Distributions\n",
      "\n",
      "The hypergeometric distribution is related to other discrete probability distributions, such as the binomial distribution, the multinomial distribution, the Poisson distribution, the negative binomial distribution, and the geometric distribution.\n",
      "\n",
      "The binomial distribution can be used as an approximation of the hypergeometric distribution when the sample size is much smaller than the population size, or when the population size is infinite.\n",
      "\n",
      "The multinomial distribution can be used to generalize the hypergeometric distribution to the case where there are more than two possible outcomes.\n",
      "\n",
      "The Poisson distribution can be used as an approximation of the hypergeometric distribution when the population size is very large and the number of successes is very small.\n",
      "\n",
      "The negative binomial distribution and the geometric distribution can be used to model the number of trials needed to obtain a certain number of successes in a sequence of independent Bernoulli trials.\n",
      "\n",
      "## References\n",
      "\n",
      "1. Casella, G., & Berger, R. L. (2002). Statistical inference (Vol. 2). Pacific Grove, CA: Duxbury.\n",
      "2. Ross, S. M. (2009). Introduction to probability and statistics for engineers and scientists (4th ed.). Amsterdam: Elsevier Academic Press.\n",
      "DONE GENERATING: hypergeometric_distribution\n",
      "NOW GENERATING: expected_value_and_variance\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"expected_value_and_variance\": {\n",
      "        \"title\": \"Expected Value and Variance\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"basic_statistics\", \"calculus\"],\n",
      "        \"further_readings\": [\"law_of_large_numbers\", \"central_limit_theorem\", \"monte_carlo_methods\", \"markov_chain_monte_carlo\", \"reinforcement_learning\", \"bayesian_inference\", \"stochastic_processes\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Expected Value and Variance\n",
      "\n",
      "Expected value and variance are two key statistical concepts that are frequently used in machine learning (ML) and artificial intelligence (AI) applications. The expected value (also known as the mean) is a measure of the central tendency of a probability distribution, while the variance measures the spread of the distribution. These concepts are fundamental to probability theory and statistics, and are used in a wide range of ML and AI algorithms, from basic decision trees to complex deep learning networks.\n",
      "\n",
      "## Expected Value\n",
      "\n",
      "The expected value of a random variable is the average value that the variable would take if the experiment were repeated many times. It is defined as:\n",
      "\n",
      "$$E[X] = \\sum_{i=1}^{n} x_i p(x_i)$$\n",
      "\n",
      "where X is a random variable, x_i is the value that X takes, and p(x_i) is the probability that X takes the value x_i. In other words, the expected value is the sum of the product of each possible value of X and its corresponding probability.\n",
      "\n",
      "The expected value has a number of important properties, including linearity, which means that the expected value of a sum of random variables is equal to the sum of their expected values:\n",
      "\n",
      "$$E[aX + bY] = aE[X] + bE[Y]$$\n",
      "\n",
      "where a and b are constants, and X and Y are random variables.\n",
      "\n",
      "## Variance\n",
      "\n",
      "The variance is a measure of the spread of a probability distribution. It is defined as:\n",
      "\n",
      "$$Var[X] = E[(X - E[X])^2]$$\n",
      "\n",
      "In other words, the variance is the expected value of the squared difference between each possible value of X and its expected value.\n",
      "\n",
      "The variance also has a number of important properties. For example, the variance of a sum of independent random variables is equal to the sum of their variances:\n",
      "\n",
      "$$Var[X + Y] = Var[X] + Var[Y]$$\n",
      "\n",
      "## Applications in ML and AI\n",
      "\n",
      "Expected value and variance are used in a wide range of ML and AI algorithms. For example, decision trees use expected value to determine which feature to split on at each node, while linear regression uses expected value to estimate the coefficients of the model. In deep learning, expected value is used in backpropagation to compute the gradients of the loss function with respect to the weights.\n",
      "\n",
      "Variance is also an important concept in ML and AI. It is used in regularization techniques, such as L2 regularization, which penalizes large weights in a model to reduce overfitting. Variance is also used in the analysis of learning algorithms, where it is used to measure the generalization error of a model.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Expected value and variance are two key statistical concepts that are fundamental to probability theory and statistics, and are used in a wide range of ML and AI algorithms. By understanding these concepts, developers can better understand the behavior of their models, and use this knowledge to improve their performance.\n",
      "DONE GENERATING: expected_value_and_variance\n",
      "NOW GENERATING: lognormal_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"lognormal_distribution\": {\n",
      "        \"title\": \"Lognormal Distribution\",\n",
      "        \"prerequisites\": [\"normal_distribution\", \"probability_distributions\", \"exponential_distribution\", \"central_limit_theorem\"],\n",
      "        \"further_readings\": [\"exponential_family\", \"gamma_distribution\", \"weibull_distribution\", \"chi_squared_distribution\", \"maximum_likelihood_estimation\", \"bayesian_inference\", \"monte_carlo_methods\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Lognormal Distribution\n",
      "\n",
      "The lognormal distribution is a continuous probability distribution of a random variable whose logarithm follows a normal distribution. It is often used to model data that is inherently non-negative and skewed, such as the size of populations, income, and stock prices.\n",
      "\n",
      "## Definition\n",
      "\n",
      "A lognormal distribution with parameters $\\mu$ and $\\sigma$ is denoted as $X\\sim \\text{Lognormal}(\\mu,\\sigma)$ and has the following probability density function:\n",
      "\n",
      "$$f_X(x)=\\frac{1}{x\\sigma\\sqrt{2\\pi}}e^{-\\frac{(\\ln x-\\mu)^2}{2\\sigma^2}}\\qquad x>0$$\n",
      "\n",
      "where $\\mu$ is the mean of the random variable's natural logarithm, and $\\sigma$ is the standard deviation of its logarithm.\n",
      "\n",
      "Its cumulative distribution function is:\n",
      "\n",
      "$$F_X(x)=\\frac{1}{2}+\\frac{1}{2}\\text{erf}\\left(\\frac{\\ln x-\\mu}{\\sigma\\sqrt{2}}\\right)\\qquad x>0$$\n",
      "\n",
      "where $\\text{erf}(x)$ is the error function.\n",
      "\n",
      "## Properties\n",
      "\n",
      "The lognormal distribution has several notable properties:\n",
      "\n",
      "- The mean and variance of a lognormal distribution are:\n",
      "\n",
      "$$\\mathbb{E}[X]=e^{\\mu+\\frac{\\sigma^2}{2}}$$\n",
      "\n",
      "$$\\text{Var}[X]=(e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2}$$\n",
      "\n",
      "- Its shape is heavily influenced by the parameters $\\mu$ and $\\sigma$. When $\\mu$ is fixed, increasing $\\sigma$ leads to a wider and more skewed distribution.\n",
      "- It is a positively skewed distribution with a long right tail. As $x$ increases, the probability density function decreases slowly but steadily.\n",
      "- The lognormal distribution is related to the normal distribution by the relationship:\n",
      "\n",
      "$$\\ln X\\sim \\text{Normal}(\\mu,\\sigma^2)$$\n",
      "\n",
      "## Applications\n",
      "\n",
      "The lognormal distribution has many applications in various fields, including finance, biology, and engineering. Some examples include:\n",
      "\n",
      "- Modeling stock prices, where the logarithmic returns follow a normal distribution but the prices themselves follow a lognormal distribution.\n",
      "- Modeling the size of biological populations, where growth is proportional to the current size and the probability of death is constant.\n",
      "- Modeling the duration of time between events that occur randomly but whose logarithms are normally distributed.\n",
      "\n",
      "## References\n",
      "\n",
      "- Johnson, N. L., Kotz, S., & Balakrishnan, N. (1994). Continuous univariate distributions, Vol. 1 (2nd ed.). Wiley.\n",
      "- Ross, S. M. (2014). Introduction to probability and statistics for engineers and scientists (5th ed.). Elsevier.\n",
      "- Wikipedia. (2021). Log-normal distribution. https://en.wikipedia.org/wiki/Log-normal_distribution\n",
      "DONE GENERATING: lognormal_distribution\n",
      "NOW GENERATING: chi_squared_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"chi_squared_distribution\": {\n",
      "        \"title\": \"Chi Squared Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"central_limit_theorem\", \"hypothesis_testing\"],\n",
      "        \"further_readings\": [\"normal_distribution\", \"t_distribution\", \"f_distribution\", \"goodness_of_fit_tests\", \"ANOVA\", \"nonparametric_statistics\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Chi Squared Distribution\n",
      "\n",
      "The Chi Squared Distribution is a continuous probability distribution that is widely used in statistical inference. It is used in a variety of applications, including hypothesis testing, goodness-of-fit tests, and analysis of variance.\n",
      "\n",
      "## Definition\n",
      "\n",
      "The Chi Squared Distribution with k degrees of freedom is denoted by χ^2(k). It is defined as the distribution of the sum of the squares of k independent standard normal random variables. That is, if Z1, Z2, ..., Zk are independent standard normal random variables, then the random variable X = Z1^2 + Z2^2 + ... + Zk^2 follows a Chi Squared Distribution with k degrees of freedom.\n",
      "\n",
      "The probability density function (PDF) of the Chi Squared Distribution with k degrees of freedom is given by:\n",
      "\n",
      "$$f(x) = \\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}e^{-x/2}$$\n",
      "\n",
      "where Γ is the gamma function.\n",
      "\n",
      "## Properties\n",
      "\n",
      "The Chi Squared Distribution has the following properties:\n",
      "\n",
      "- The mean of the Chi Squared Distribution with k degrees of freedom is k.\n",
      "- The variance of the Chi Squared Distribution with k degrees of freedom is 2k.\n",
      "- The Chi Squared Distribution is skewed to the right for k ≤ 2 and becomes more symmetric as k increases.\n",
      "- As k approaches infinity, the Chi Squared Distribution approaches a normal distribution with mean k and variance 2k.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Chi Squared Distribution is used in a variety of statistical inference applications, including:\n",
      "\n",
      "- Hypothesis testing: The Chi Squared Distribution is used to test whether a sample comes from a specified distribution. For example, it can be used to test whether a set of observations is normally distributed or whether two or more samples come from the same population.\n",
      "- Goodness-of-fit tests: The Chi Squared Distribution is used to test whether a set of observations comes from a specified distribution. For example, it can be used to test whether a set of observed frequencies matches a set of expected frequencies.\n",
      "- Analysis of variance (ANOVA): The Chi Squared Distribution is used to test for differences between two or more groups in a study. It can be used to test whether the means of the groups are equal or whether the variances of the groups are equal.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The Chi Squared Distribution is a useful probability distribution in statistical inference. It is used in a variety of applications, including hypothesis testing, goodness-of-fit tests, and analysis of variance. Understanding the properties of the Chi Squared Distribution is important for anyone working in statistics or data science.\n",
      "DONE GENERATING: chi_squared_distribution\n",
      "NOW GENERATING: student's_t_distribution\n",
      "FINISH_REASON: stop\n",
      "{\n",
      "    \"students_t_distribution\": {\n",
      "        \"title\": \"Student's T Distribution\",\n",
      "        \"prerequisites\": [\"probability_distributions\", \"normal_distribution\", \"hypothesis_testing\", \"central_limit_theorem\"],\n",
      "        \"further_readings\": [\"chi_squared_distribution\", \"ANOVA\", \"regression_analysis\", \"confidence_intervals\"]\n",
      "    }\n",
      "}\n",
      "\n",
      "# Student's T Distribution\n",
      "\n",
      "The Student's T distribution is a probability distribution that is widely used in statistical inference, particularly in hypothesis testing. It was first introduced by William Sealy Gosset in 1908 under the pseudonym \"Student\". \n",
      "\n",
      "The distribution arises when the population standard deviation is unknown and must be estimated from the sample. In such cases, the standard normal distribution cannot be used to calculate probabilities and confidence intervals. Instead, the Student's T distribution is used.\n",
      "\n",
      "## Definition\n",
      "\n",
      "Suppose we have a random sample of size n from a normal population with unknown mean μ and unknown standard deviation σ. Let X̄ be the sample mean and S be the sample standard deviation. Then the Student's T distribution with n - 1 degrees of freedom is defined as:\n",
      "\n",
      "$$T = \\frac{X̄ - μ}{S/\\sqrt{n}}$$\n",
      "\n",
      "where T has a T-distribution with n - 1 degrees of freedom.\n",
      "\n",
      "## Properties\n",
      "\n",
      "- The Student's T distribution is symmetric and bell-shaped like the normal distribution.\n",
      "\n",
      "- The shape of the distribution depends on the number of degrees of freedom. As the degrees of freedom increase, the distribution approaches the normal distribution.\n",
      "\n",
      "- The mean of the Student's T distribution is 0, and the variance is n/(n-2) if n > 2.\n",
      "\n",
      "- The T statistic can be used to test hypotheses about the population mean μ. For example, if we want to test whether the mean of a population is equal to a given value μ0, we can calculate the T statistic and compare it to the critical values from the T distribution with n-1 degrees of freedom.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The Student's T distribution is widely used in hypothesis testing and confidence interval estimation. It is also used in regression analysis, where the T statistic is used to test the significance of the regression coefficients. Additionally, the T distribution is used in one-way ANOVA to test for differences between means of several groups.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The Student's T distribution is an important probability distribution that is widely used in statistical inference. It is used when the population standard deviation is unknown and must be estimated from the sample. The distribution has many important properties that make it useful in hypothesis testing and confidence interval estimation.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"student's_t_distribution\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwiki-connections.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     56\u001b[0m     wiki_connections \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(file)\n\u001b[0;32m---> 57\u001b[0m     queue \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m wiki_connections[topic][\u001b[39m'\u001b[39m\u001b[39mprerequisites\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m     queue \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m wiki_connections[topic][\u001b[39m'\u001b[39m\u001b[39mfurther_readings\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDONE GENERATING:\u001b[39m\u001b[39m'\u001b[39m, topic)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"student's_t_distribution\""
     ]
    }
   ],
   "source": [
    "visited_pages = load_visited_pages()\n",
    "queue = ['f1_score']\n",
    "# visited_pages.remove('bayesian_optimization')\n",
    "\n",
    "if not queue:\n",
    "    with open('wiki-connections.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for key in data:\n",
    "            for new_topic in data[key]['prerequisites']:\n",
    "                if new_topic not in visited_pages and new_topic not in queue and new_topic not in data:\n",
    "                    queue.append(new_topic)\n",
    "            for new_topic in data[key]['further_readings']:\n",
    "                if new_topic not in visited_pages and new_topic not in queue and new_topic not in data:\n",
    "                    queue.append(new_topic)\n",
    "            if len(queue) > 0:\n",
    "                break\n",
    "\n",
    "\n",
    "while queue:\n",
    "    topic = queue.pop(0)\n",
    "    topic = topic.lower()\n",
    "    topic = topic.replace(\"'\", \"\")\n",
    "\n",
    "    if topic in visited_pages:\n",
    "        continue\n",
    "\n",
    "    with open('wiki-connections.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        if topic in data:\n",
    "            continue\n",
    "        while len(queue) == 0:\n",
    "            for key in data:\n",
    "                for new_topic in data[key]['prerequisites']:\n",
    "                    if new_topic not in visited_pages and new_topic not in queue and new_topic != topic and new_topic not in data:\n",
    "                        queue.append(new_topic)\n",
    "                for new_topic in data[key]['further_readings']:\n",
    "                    if new_topic not in visited_pages and new_topic not in queue and new_topic != topic and new_topic not in data:\n",
    "                        queue.append(new_topic)\n",
    "\n",
    "    print('NOW GENERATING:', topic)\n",
    "    prompt = generate_prompt(topic)\n",
    "    finish_reason, message, completion = generate_completion(prompt)\n",
    "    print(\"FINISH_REASON:\", finish_reason)\n",
    "    print(message)\n",
    "\n",
    "    if finish_reason != 'stop':\n",
    "        print(\"Error: Did not finish generating.\")\n",
    "        exit(1)\n",
    "    \n",
    "    generate_json(message, topic)\n",
    "    generate_markdown(message, topic)\n",
    "    generate_js(topic)\n",
    "\n",
    "    visited_pages.add(topic)\n",
    "    save_visited_pages(visited_pages)\n",
    "\n",
    "    with open('wiki-connections.json', 'r') as file:\n",
    "        wiki_connections = json.load(file)\n",
    "        queue += wiki_connections[topic]['prerequisites']\n",
    "        queue += wiki_connections[topic]['further_readings']\n",
    "\n",
    "    print('DONE GENERATING:', topic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
