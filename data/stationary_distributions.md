# Stationary Distributions

In the context of probability theory and Markov chains, a stationary distribution is a probability distribution that remains unchanged as time progresses. More formally, a stationary distribution is a probability distribution $\pi$ over the states of a Markov chain such that the distribution remains the same after applying the transition probabilities of the chain. This concept is essential in various fields, including artificial intelligence, machine learning, and statistical physics.

## Markov Chains

A Markov chain is a stochastic process that models a sequence of events, where the probability of each event depends only on the state attained in the previous event. A Markov chain is defined by a set of states $S$, an initial state distribution $p_0$, and a transition probability matrix $P$. The transition probability matrix $P$ is a square matrix with dimensions $|S| \times |S|$, where the entry $P_{ij}$ represents the probability of transitioning from state $i$ to state $j$.

## Definition of Stationary Distribution

A stationary distribution $\pi$ for a Markov chain with transition probability matrix $P$ is a probability distribution over the states of the chain such that:


$$

\pi = \pi P

$$


In other words, the stationary distribution remains unchanged after applying the transition probabilities of the chain. It is important to note that not all Markov chains have a stationary distribution. However, if a Markov chain is irreducible (meaning that it is possible to reach any state from any other state) and aperiodic (meaning that the chain does not have a fixed cycle length), then it has a unique stationary distribution.

## Properties of Stationary Distributions

1. **Existence**: A finite Markov chain has a stationary distribution if and only if it is irreducible and aperiodic. This result is known as the Perron-Frobenius theorem.

2. **Uniqueness**: If a Markov chain has a stationary distribution, it is unique.

3. **Convergence**: If a Markov chain has a stationary distribution $\pi$, then the distribution of the chain converges to $\pi$ as time goes to infinity, regardless of the initial state distribution. This property is known as the convergence to stationarity and can be formally expressed as:

   
$$

   \lim_{n \to \infty} p_0 P^n = \pi
   
$$


   where $p_0$ is the initial state distribution and $P^n$ is the $n$-th power of the transition probability matrix.

4. **Reversibility**: A stationary distribution $\pi$ is said to be reversible if it satisfies the detailed balance condition:

   
$$

   \pi_i P_{ij} = \pi_j P_{ji}
   
$$


   for all states $i$ and $j$. Reversibility is a useful property in the analysis of Markov chains, as it simplifies the computation of stationary distributions and allows for the application of techniques from equilibrium statistical mechanics.

## Applications of Stationary Distributions

Stationary distributions play a crucial role in various fields, including artificial intelligence, machine learning, and statistical physics. Some of the applications of stationary distributions are:

1. **Markov Decision Processes**: In reinforcement learning, Markov decision processes (MDPs) are used to model decision-making problems. The stationary distribution of an MDP can be used to analyze the long-term behavior of the system and to compute the expected reward under a given policy.

2. **Hidden Markov Models**: In speech recognition and natural language processing, hidden Markov models (HMMs) are used to model sequences of observations generated by an underlying Markov chain. The stationary distribution of the hidden Markov chain can be used to compute the prior probabilities of the hidden states and to initialize the parameters of the model.

3. **Gibbs Sampling**: In Bayesian statistics, Gibbs sampling is a Markov chain Monte Carlo (MCMC) method used to generate samples from a joint probability distribution. The stationary distribution of the Gibbs sampler corresponds to the target distribution, and the convergence to stationarity guarantees that the generated samples are representative of the target distribution.

4. **Metropolis-Hastings Algorithm**: The Metropolis-Hastings algorithm is another MCMC method used to generate samples from a target probability distribution. The stationary distribution of the Metropolis-Hastings chain corresponds to the target distribution, and the convergence to stationarity ensures that the generated samples are representative of the target distribution.

## Conclusion

Stationary distributions are an essential concept in probability theory and Markov chains, with numerous applications in artificial intelligence, machine learning, and statistical physics. The properties of stationary distributions, such as existence, uniqueness, convergence, and reversibility, provide valuable insights into the long-term behavior of Markov chains and enable the development of powerful algorithms for sampling, inference, and decision-making.
