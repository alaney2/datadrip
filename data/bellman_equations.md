# Bellman Equations

Bellman equations are a set of recursive equations that are used to solve optimization problems in dynamic programming and reinforcement learning. These equations were developed by Richard Bellman in the 1950s, and have since become a fundamental tool in these fields.

## Dynamic Programming

Dynamic programming refers to a class of algorithms that solve optimization problems. These algorithms typically involve breaking down a larger problem into smaller subproblems, and then solving these subproblems recursively. Dynamic programming is particularly useful in problems where the optimal solution can be found by combining the optimal solutions to smaller subproblems.

## Markov Decision Process

A Markov decision process (MDP) is a mathematical framework used to model decision-making problems in which outcomes are partly random and partly under the control of a decision maker. MDPs are used in many fields, including finance, economics, engineering, and computer science.

## Value Iteration Algorithm

The value iteration algorithm is a dynamic programming algorithm used to solve MDPs. This algorithm involves iteratively updating estimates of the optimal value function for each state in the MDP. The value function represents the expected cumulative reward that can be obtained by following the optimal policy from a given state.

## Q-Learning

Q-learning is a reinforcement learning algorithm that learns an optimal policy by estimating the optimal action-value function (also known as the Q-function). The Q-function represents the expected cumulative reward that can be obtained by taking a particular action in a given state, and then following the optimal policy thereafter.

## Reinforcement Learning Algorithms

Reinforcement learning is a subfield of machine learning that involves learning from experience in order to make better decisions. Reinforcement learning algorithms typically involve an agent that interacts with an environment, and receive rewards or punishments based on its actions.

## Further Readings

- Temporal Difference Learning
- Actor-Critic Methods
- Deep Q-Networks
- Monte Carlo Methods
- Policy Gradient Methods
