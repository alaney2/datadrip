# Exploration Vs Exploitation

In machine learning, exploration is the act of gathering more information to improve the model. Exploitation is the act of using the information the model already has to make decisions. The exploration-exploitation trade-off is a major challenge in reinforcement learning.

## Reinforcement Learning

Reinforcement learning is a type of machine learning that focuses on training agents to make decisions in an environment to maximize a reward signal. The agent interacts with the environment by taking actions, and the environment returns a reward signal that the agent tries to maximize.

## Multi-Armed Bandits

Multi-armed bandits are a type of problem in reinforcement learning where the agent has to choose between multiple actions, each with an unknown reward distribution. The agent has to balance exploration of new actions with exploitation of the actions that have already been tried.

## Markov Decision Processes

Markov decision processes are a mathematical framework for modeling decision-making in an environment. The environment is modeled as a sequence of time steps, and the agent takes actions at each time step. The state of the environment at each time step is modeled as a Markov process.

## Policy Gradient Methods

Policy gradient methods are a type of reinforcement learning algorithm that directly optimize the policy of the agent. The policy is a function that maps states to actions. The algorithm updates the policy by following the gradient of the expected reward with respect to the policy parameters.

## Value Iteration

Value iteration is a reinforcement learning algorithm that computes the optimal value function for a given Markov decision process. The value function is a function that maps states to the expected total reward from that state to the end of the episode. The algorithm iteratively updates the value function until convergence.

## Monte Carlo Methods

Monte Carlo methods are a type of reinforcement learning algorithm that estimates the value of a state or action by averaging the returns from many simulated episodes. The algorithm samples actions according to the policy and then simulates the environment to get the returns.

## Further Readings

- Bayesian optimization
- Thompson sampling
- UCB algorithm
- Epsilon-greedy algorithm
- Online learning
- Contextual bandits
- Exploration strategies
- Active learning
- Bandit algorithms for preference learning
