# Hierarchical Multi Agent Reinforcement Learning

Hierarchical Multi Agent Reinforcement Learning (HMARL) is a subfield of Reinforcement Learning (RL) that deals with the coordination of multiple agents in a hierarchical manner. In HMARL, agents are organized into a hierarchy of sub-tasks, where each sub-task is responsible for a specific goal. The agents at each level of the hierarchy learn to coordinate with each other to achieve their respective goals.

## Overview

In HMARL, the agents are organized into a hierarchy of sub-tasks, where each sub-task is responsible for a specific goal. The agents at each level of the hierarchy learn to coordinate with each other to achieve their respective goals. The hierarchy can be organized in a variety of ways, such as a tree or a graph. The agents at the lower levels of the hierarchy are responsible for more specific tasks, while the agents at the higher levels are responsible for more general tasks.

## Applications

HMARL has a wide range of applications, such as in robotics, where multiple robots need to coordinate with each other to perform a task. It can also be used in traffic management, where multiple agents need to coordinate with each other to optimize traffic flow. HMARL can also be used in video games, where multiple agents need to coordinate with each other to achieve a common goal.

## Prerequisites

To understand HMARL, one should have a good understanding of Reinforcement Learning, Multi-Agent Systems, and Deep Learning.

## Further Readings

- Hierarchical Reinforcement Learning
- Multi-Agent Reinforcement Learning
- Distributed Reinforcement Learning
